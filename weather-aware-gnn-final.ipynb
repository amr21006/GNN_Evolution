{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\nOptimized Construction Logistics Optimization System\nwith Weather-Aware GNN and Multi-Objective GA\n\"\"\"\n\n# Install required libraries\n!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -q\n!pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu118.html -q\n!pip install torch_geometric -q\n!pip install openmeteo-requests requests-cache retry-requests numpy pandas networkx scikit-learn deap matplotlib graphviz -q\n\n# Import libraries\nimport openmeteo_requests\nimport requests_cache\nimport pandas as pd\nfrom retry_requests import retry\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport random\nimport time\nfrom datetime import datetime, timedelta\nimport math\nfrom math import sqrt\nimport copy\nfrom functools import lru_cache\nimport hashlib\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Tuple, Optional\nimport unittest\n\n# PyTorch and PyG imports\nimport torch\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import SAGEConv, GATConv, DataParallel\nimport torch.nn.functional as F\n\n# GA and other utility imports\nfrom deap import base, creator, tools, algorithms\n\nprint(\"âœ… Setup Complete. All libraries installed and imported.\")\n\n# Configuration Management\n@dataclass\nclass ExperimentConfig:\n    \"\"\"Centralized configuration for the entire experiment\"\"\"\n    site_graph: str = \"large_scale\"\n    weather_aware: bool = True\n    optimization_method: str = \"NSGA2\"\n    vehicle_types: List[str] = None\n    risk_tolerance: float = 0.5\n    simulation_duration_hours: int = 168\n    num_ga_generations: int = 70\n    population_size: int = 100\n    gnn_hidden_channels: int = 64\n    batch_size: int = 32\n    \n    def __post_init__(self):\n        if self.vehicle_types is None:\n            self.vehicle_types = ['truck', 'forklift']\n\n# Global configuration\nconfig = ExperimentConfig()\n\nclass RandomSeedManager:\n    \"\"\"Manager for reproducible results\"\"\"\n    @staticmethod\n    def set_seeds(seed=42):\n        random.seed(seed)\n        np.random.seed(seed)\n        torch.manual_seed(seed)\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed_all(seed)\n\nRandomSeedManager.set_seeds(42)\n\nprint(\"âœ… Configuration and random seeds set.\")","metadata":{"_uuid":"70c433c6-d73d-49de-a6a9-05e8cc9c73cc","_cell_guid":"696a790b-7ed9-423c-9802-5d601ce79183","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-30T09:18:28.533992Z","iopub.execute_input":"2025-09-30T09:18:28.534463Z","iopub.status.idle":"2025-09-30T09:18:41.301984Z","shell.execute_reply.started":"2025-09-30T09:18:28.534439Z","shell.execute_reply":"2025-09-30T09:18:41.301192Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import networkx as nx\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nimport numpy as np\nimport random\n\nclass SiteGraphGenerator:\n    \"\"\"Generates realistic construction site graphs with specialized zones\"\"\"\n    \n    @staticmethod\n    def create_large_scale_site_graph():\n        \"\"\"\n        Creates a more complex and realistic construction site graph, representing a larger project\n        with specialized zones and structured traffic flow.\n        \"\"\"\n        G = nx.DiGraph()\n\n        # Define a larger set of nodes with specialized roles and positions for visualization\n        node_positions = {\n            # Entry, Exit & Main Logistics Hubs\n            'Main_Gate': (0, 50),\n            'Contractor_Gate': (0, 150),\n            'Laydown_A': (20, 120),       # Steel & Rebar Storage\n            'Laydown_B': (20, 30),        # General Materials Storage\n            'Fabrication_Yard': (180, 130), # Prefabrication Area\n            'Fuel_Depot': (100, 0),         # Refueling Station\n            'Waste_Disposal': (180, 20),    # Waste & Debris Collection\n\n            # Work Zones (Representing multiple buildings or major areas)\n            'Building_1_N': (80, 180),      # North side of Building 1\n            'Building_1_S': (80, 140),      # South side of Building 1\n            'Building_2_W': (150, 100),     # West side of Building 2\n            'Building_2_E': (180, 100),     # East side of Building 2\n            'Foundation_Pit': (120, 60),    # Major excavation area\n        }\n        \n        for node, pos in node_positions.items():\n            G.add_node(node, pos=pos)\n\n        # Define a more extensive edge network, including one-way roads to manage traffic flow\n        edge_definitions = [\n            # Main access loop (designed as a one-way circulation road)\n            ('Main_Gate', 'Laydown_B', {'paved': True, 'one_way': True}),\n            ('Laydown_B', 'Fuel_Depot', {'paved': True, 'one_way': True}),\n            ('Fuel_Depot', 'Waste_Disposal', {'paved': True, 'one_way': True}),\n            ('Waste_Disposal', 'Building_2_E', {'paved': True, 'one_way': True}),\n            ('Building_2_E', 'Fabrication_Yard', {'paved': True, 'one_way': True}),\n            ('Fabrication_Yard', 'Building_1_N', {'paved': True, 'one_way': True}),\n            ('Building_1_N', 'Contractor_Gate', {'paved': True, 'one_way': True}),\n            ('Contractor_Gate', 'Laydown_A', {'paved': True, 'one_way': True}),\n            ('Laydown_A', 'Building_1_S', {'paved': True, 'one_way': True}),\n            ('Building_1_S', 'Main_Gate', {'paved': True, 'one_way': True}),\n\n            # Two-way connector paths and access roads to work zones\n            ('Laydown_A', 'Laydown_B', {'paved': True}),\n            ('Building_1_S', 'Foundation_Pit', {'paved': False}), # Unpaved access to pit\n            ('Foundation_Pit', 'Building_2_W', {'paved': False}), # Unpaved access to pit\n            ('Building_2_W', 'Building_2_E', {'paved': True}),\n            ('Building_1_S', 'Laydown_A', {'paved': True}), # Short-cut\n            ('Fuel_Depot', 'Foundation_Pit', {'paved': False}), # Direct unpaved access\n        ]\n\n        for u, v, attrs in edge_definitions:\n            # Calculate length from positions and add some noise for realism\n            pos_u, pos_v = np.array(node_positions[u]), np.array(node_positions[v])\n            # Use Euclidean distance scaled up to represent meters on a large site\n            length = np.linalg.norm(pos_u - pos_v) * 1.5\n            attrs['length'] = int(length)\n            attrs['slope'] = random.randint(-4, 4) # Assign a random slope\n            attrs['base_speed_limit'] = 10 if attrs.get('paved', False) else 5\n            attrs['base_travel_time'] = attrs['length'] / attrs['base_speed_limit']\n\n            G.add_edge(u, v, **attrs)\n            # If not explicitly a one-way road, add the reverse edge\n            if not attrs.get('one_way', False):\n                # Create a new attribute dict for the reverse edge to allow different slopes\n                rev_attrs = attrs.copy()\n                rev_attrs['slope'] = -attrs['slope']\n                G.add_edge(v, u, **rev_attrs)\n\n        return G, node_positions\n\n    @staticmethod\n    def visualize_graph(graph, node_positions, title=\"Construction Site Layout\"):\n        \"\"\"Visualize the site graph with proper styling\"\"\"\n        paved_edges = [edge for edge, attrs in graph.edges.items() if attrs.get('paved', False)]\n        unpaved_edges = [edge for edge, attrs in graph.edges.items() if not attrs.get('paved', False)]\n\n        plt.figure(figsize=(20, 14))\n        # Draw nodes and labels\n        nx.draw_networkx_nodes(graph, node_positions, node_size=3500, node_color='skyblue')\n        nx.draw_networkx_labels(graph, node_positions, font_size=10, font_weight='bold')\n\n        # Draw edges with different styles\n        nx.draw_networkx_edges(graph, node_positions, edgelist=paved_edges,\n                               width=2.0, alpha=0.7, edge_color='black',\n                               connectionstyle='arc3,rad=0.1', arrowsize=20)\n        nx.draw_networkx_edges(graph, node_positions, edgelist=unpaved_edges,\n                               width=1.5, alpha=0.8, edge_color='brown', style='dashed',\n                               connectionstyle='arc3,rad=0.1', arrowsize=20)\n\n        plt.title(title, fontsize=22)\n        plt.xlabel(\"X Coordinate (m)\")\n        plt.ylabel(\"Y Coordinate (m)\")\n        plt.grid(True)\n        plt.legend(handles=[plt.Line2D([0], [0], color='black', lw=2, label='Paved Road'),\n                             plt.Line2D([0], [0], color='brown', lw=2, ls='--', label='Unpaved Path')],\n                   fontsize=14)\n        plt.show()\n\n# --- Initialization and Schedule Definition ---\nsite_graph, node_positions = SiteGraphGenerator.create_large_scale_site_graph()\n\n# Define 4D scheduled closures\nSCHEDULED_CLOSURES = {\n    ('Foundation_Pit', 'Building_2_W'): (datetime.fromisoformat(\"2023-07-01T13:00:00\"), datetime.fromisoformat(\"2023-07-01T15:00:00\")),\n    ('Building_2_W', 'Foundation_Pit'): (datetime.fromisoformat(\"2023-07-01T13:00:00\"), datetime.fromisoformat(\"2023-07-01T15:00:00\"))\n}\n\nprint(f\"âœ… Large-scale site graph created with {site_graph.number_of_nodes()} nodes and {site_graph.number_of_edges()} edges.\")\n\n# Visualize the graph\nSiteGraphGenerator.visualize_graph(site_graph, node_positions, \"Large-Scale Construction Site Layout\")","metadata":{"_uuid":"c156732b-dccc-4d45-8777-965b30ccec57","_cell_guid":"b8f999f6-bf66-4a80-bdc2-04d061f0fb25","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-30T09:18:41.303726Z","iopub.execute_input":"2025-09-30T09:18:41.304312Z","iopub.status.idle":"2025-09-30T09:18:41.833218Z","shell.execute_reply.started":"2025-09-30T09:18:41.304245Z","shell.execute_reply":"2025-09-30T09:18:41.832489Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class StaticOptimizer:\n    \"\"\"\n    A simple baseline optimizer that creates a static, round-robin plan.\n    It does not use GNNs, weather data, or adaptive re-planning.\n    \"\"\"\n    def run_static_optimizer(self, jobs, states, graph):\n        \"\"\"\n        Creates a simple round-robin assignment of jobs to vehicles.\n        \"\"\"\n        print(\"--- Running Optimizer: Static Baseline (Round-Robin) ---\")\n        job_ids = [job['id'] for job in jobs]\n        \n        # Simple round-robin plan\n        plan = [[] for _ in states]\n        for i, job_id in enumerate(job_ids):\n            plan[i % len(states)].append(job_id)\n            \n        print(\"âœ… Static optimization complete.\")\n        return plan, job_ids # Returning job_ids as the permutation for simulation\n\n\n# --- REVISED SyntheticDataGenerator ---\n# This version uses more justifiable physics models and is more modular.\n\nfrom scipy.special import expit # Sigmoid function for a smoother penalty\n\nclass SyntheticDataGenerator:\n    \"\"\"Generates synthetic construction logistics data with more realistic physics\"\"\"\n    \n    # Fleet & Simulation Configuration\n    VEHICLE_PROPERTIES = {\n        # Fuel rates in Liters per Second. \n        # Source: Adapted from construction equipment fuel consumption studies.\n        'truck': {\n            'base_speed_multiplier': 1.0, 'weather_sensitivity': 1.0,\n            'base_fuel_rate': 0.002, # Idle: 7.2 L/hr\n            'load_fuel_factor': 1.5, # Fuel rate under load\n        },\n        'forklift': {\n            'base_speed_multiplier': 0.6, 'weather_sensitivity': 1.5,\n            'base_fuel_rate': 0.001, # Idle: 3.6 L/hr\n            'load_fuel_factor': 1.8,\n        }\n    }\n    SIMULATION_START_TIME = datetime.fromisoformat(\"2023-07-01T07:00:00\")\n    \n    def __init__(self, site_graph, weather_df, scheduled_closures):\n        self.site_graph = site_graph\n        self.weather_df = weather_df\n        self.scheduled_closures = scheduled_closures\n\n    @staticmethod\n    def get_weather_at_time(sim_time, weather_df):\n        indexer = weather_df.index.get_indexer([sim_time], method='nearest')\n        return weather_df.iloc[indexer[0]]\n\n    def calculate_travel_factors(self, edge_data, num_vehicles_on_edge, weather, vehicle_type, soil_condition):\n        \"\"\"Calculates delay factors based on various conditions.\"\"\"\n        vehicle_props = self.VEHICLE_PROPERTIES[vehicle_type]\n        \n        # BPR Congestion Model (Bureau of Public Roads)\n        # alpha=0.15, beta=4 are common parameters. Capacity assumed to be 5 vehicles/edge/hour.\n        capacity_per_edge = 5 \n        congestion_factor = 1.0 + 0.15 * (num_vehicles_on_edge / capacity_per_edge)**4\n        \n        # Weather & Soil Impact Factor\n        weather_soil_factor = 1.0\n        variance_factor = 0.05 # Base variance\n        \n        rain_idx, heat_idx, soil_idx = int(weather['rain_intensity']), int(weather['heat_stress']), int(soil_condition)\n\n        # Rain slows down all vehicles and increases variance. CITE: Construction productivity literature.\n        rain_penalties = [0, 0.1, 0.4, 0.7]\n        weather_soil_factor += rain_penalties[rain_idx] * vehicle_props['weather_sensitivity']\n        variance_factor += [0, 0.1, 0.3, 0.2][rain_idx]\n        \n        # Unpaved roads are heavily affected by soil condition. CITE: Off-road vehicle dynamics papers.\n        if not edge_data['paved']:\n            soil_penalties = [1.0, 1.5, 3.0]\n            weather_soil_factor *= soil_penalties[soil_idx]\n            variance_factor += [0, 0.2, 0.4][soil_idx]\n\n        return congestion_factor, weather_soil_factor, variance_factor\n\n    def calculate_fuel_consumption(self, edge_data, travel_time, vehicle_type, soil_condition):\n        \"\"\"Calculates fuel based on physics. CITE: CMEM or similar vehicle energy models.\"\"\"\n        vehicle_props = self.VEHICLE_PROPERTIES[vehicle_type]\n        \n        # Start with fuel consumed during travel time under load\n        fuel_consumed = vehicle_props['base_fuel_rate'] * vehicle_props['load_fuel_factor'] * travel_time\n        \n        # Add penalty for positive slope (gravity resistance)\n        slope_penalty = max(0, edge_data['slope']) * 0.15 \n        \n        # Add penalty for poor ground conditions (rolling resistance)\n        soil_idx = int(soil_condition)\n        soil_penalty = 0\n        if not edge_data['paved']:\n            soil_penalties = [0, 0.8, 2.5] # 80% and 250% more fuel\n            soil_penalty = soil_penalties[soil_idx]\n            \n        fuel_consumed *= (1 + slope_penalty + soil_penalty)\n        return fuel_consumed\n\n    def calculate_ground_truth_travel(self, edge_data, num_vehicles_on_edge, weather, vehicle_type, current_time, soil_condition):\n        \"\"\"The 'physics engine' of our simulation, now with improved models.\"\"\"\n        edge_key = (edge_data['start_node'], edge_data['end_node'])\n        if edge_key in self.scheduled_closures:\n            start_block, end_block = self.scheduled_closures[edge_key]\n            if start_block <= current_time <= end_block:\n                return float('inf'), 0.0, 0.0\n        \n        vehicle_props = self.VEHICLE_PROPERTIES[vehicle_type]\n        base_time = edge_data['base_travel_time'] / vehicle_props['base_speed_multiplier']\n        \n        congestion_factor, weather_soil_factor, variance_factor = self.calculate_travel_factors(\n            edge_data, num_vehicles_on_edge, weather, vehicle_type, soil_condition\n        )\n        \n        mean_time = base_time * congestion_factor * weather_soil_factor\n        variance = (base_time * variance_factor)**2\n        \n        fuel_consumed = self.calculate_fuel_consumption(edge_data, mean_time, vehicle_type, soil_condition)\n        \n        return mean_time, variance, fuel_consumed\n\n    # The generate_synthetic_data method would remain largely the same, but now it calls the new, more robust physics functions.\n    def generate_synthetic_data(self, num_samples=15000):\n        # ... (rest of the function is the same as your original) ...\n        # [This function now generates much more realistic and justifiable data for GNN training]\n        print(\"ðŸš€ Starting synthetic data generation (with improved physics)...\")\n        edge_traversal_log = []\n\n        for i in range(num_samples):\n            # ... (the rest is the same) ...\n            u, v, edge_attrs = random.choice(list(self.site_graph.edges(data=True)))\n            sim_time = self.SIMULATION_START_TIME + timedelta(hours=random.uniform(0, config.simulation_duration_hours))\n            weather_now = self.get_weather_at_time(sim_time, self.weather_df)\n            vehicle_type = random.choice(['truck', 'forklift'])\n            num_on_edge = random.randint(0, 5)\n\n            soil = 0\n            if not edge_attrs['paved']:\n                recent_weather = self.weather_df[sim_time - timedelta(hours=3):sim_time]\n                if not recent_weather.empty:\n                    max_recent_rain = recent_weather['rain_intensity'].max()\n                    if max_recent_rain >= 2: soil = 2\n                    elif max_recent_rain == 1: soil = 1\n\n            edge_attrs_with_nodes = {**edge_attrs, 'start_node': u, 'end_node': v}\n            mean_time, variance, fuel = self.calculate_ground_truth_travel(\n                edge_attrs_with_nodes, num_on_edge, weather_now, vehicle_type, sim_time, soil\n            )\n\n            if mean_time != float('inf'):\n                log_entry = {\n                    'edge_start_node': u, 'edge_end_node': v,\n                    'mean_travel_time': mean_time,\n                    'variance': variance,\n                    'fuel_consumed': fuel,\n                    'time_of_day': sim_time.hour + sim_time.minute / 60.0,\n                    'num_vehicles_on_edge': num_on_edge,\n                    **weather_now.to_dict(),\n                    'soil_condition': soil,\n                    'vehicle_type_truck': 1 if vehicle_type == 'truck' else 0\n                }\n                edge_traversal_log.append(log_entry)\n\n        dataset_df = pd.DataFrame(edge_traversal_log)\n        print(f\"\\\\nâœ… Synthetic data generation complete. Generated {len(dataset_df)} records.\")\n        return dataset_df","metadata":{"_uuid":"610f7a4c-4ab3-40d4-8996-2077a422c005","_cell_guid":"363c427a-4cd8-42ec-b780-84e87b44c2b5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-30T09:31:14.364997Z","iopub.execute_input":"2025-09-30T09:31:14.365752Z","iopub.status.idle":"2025-09-30T09:31:14.381583Z","shell.execute_reply.started":"2025-09-30T09:31:14.365720Z","shell.execute_reply":"2025-09-30T09:31:14.380803Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import openmeteo_requests\nimport requests_cache\nimport pandas as pd\nfrom retry_requests import retry\nimport matplotlib.pyplot as plt\n\nclass WeatherDataManager:\n    \"\"\"Manages weather data fetching and feature engineering\"\"\"\n    \n    def __init__(self):\n        self.cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n        self.retry_session = retry(self.cache_session, retries=5, backoff_factor=0.2)\n        self.openmeteo = openmeteo_requests.Client(session=self.retry_session)\n\n    def get_weather_data(self, latitude, longitude, start_date, end_date):\n        \"\"\"\n        Fetches historical hourly weather data from the Open-Meteo API.\n        It uses caching to avoid re-downloading data during development.\n        \"\"\"\n        # Define the API request parameters\n        url = \"https://archive-api.open-meteo.com/v1/archive\"\n        params = {\n            \"latitude\": latitude,\n            \"longitude\": longitude,\n            \"start_date\": start_date,\n            \"end_date\": end_date,\n            \"hourly\": [\"temperature_2m\", \"rain\", \"wind_speed_10m\"]\n        }\n\n        # Make the API call\n        responses = self.openmeteo.weather_api(url, params=params)\n        response = responses[0]\n\n        # Process the response into a Pandas DataFrame\n        hourly = response.Hourly()\n        hourly_data = {\n            \"temperature_2m\": hourly.Variables(0).ValuesAsNumpy(),\n            \"rain\": hourly.Variables(1).ValuesAsNumpy(),\n            \"wind_speed_10m\": hourly.Variables(2).ValuesAsNumpy(),\n        }\n        df = pd.DataFrame(data=hourly_data)\n\n        # Create a robust DatetimeIndex from the API's metadata\n        start = pd.to_datetime(hourly.Time(), unit=\"s\")\n        end = pd.to_datetime(hourly.TimeEnd(), unit=\"s\")\n        interval = pd.Timedelta(seconds=hourly.Interval())\n        df.index = pd.date_range(start=start, end=end, freq=interval, inclusive=\"left\")\n\n        return df\n\n    @staticmethod\n    def feature_engineer_weather(df):\n        \"\"\"\n        Adds engineered, construction-relevant features to the raw weather dataframe.\n        These categorical features are easier for a machine learning model to interpret.\n        \"\"\"\n        # Create rain intensity buckets (0: None, 1: Light, 2: Moderate, 3: Heavy)\n        # Thresholds are based on standard meteorological definitions (mm/hr)\n        df['rain_intensity'] = pd.cut(df['rain'],\n                                      bins=[-1, 0.1, 2.5, 7.6, 100],\n                                      labels=[0, 1, 2, 3],\n                                      right=True).astype(int)\n\n        # Create wind hazard flag (0: Safe, 1: Hazardous)\n        # Threshold based on levels where light equipment operation becomes risky (~55 km/h)\n        df['wind_hazard'] = (df['wind_speed_10m'] > 15).astype(int)\n\n        # Create heat stress buckets (0: Normal, 1: High, 2: Very High)\n        # Thresholds based on general guidance for outdoor work safety\n        df['heat_stress'] = pd.cut(df['temperature_2m'],\n                                   bins=[-100, 28, 32, 100],\n                                   labels=[0, 1, 2],\n                                   right=False).astype(int)\n        return df\n\n    @staticmethod\n    def visualize_weather_features(weather_df, days=5):\n        \"\"\"Visualize engineered weather features\"\"\"\n        sample_data = weather_df.first(f'{days}D')\n        fig, axes = plt.subplots(3, 1, figsize=(15, 10), sharex=True)\n\n        # Plot 1: Rain and Rain Intensity\n        ax1_twin = axes[0].twinx()\n        sample_data['rain'].plot(ax=axes[0], color='blue', label='Rain (mm/hr)', style='-')\n        sample_data['rain_intensity'].plot(ax=ax1_twin, color='red', label='Rain Intensity (Category)', drawstyle='steps-post')\n        axes[0].set_ylabel(\"Rain (mm/hr)\")\n        ax1_twin.set_ylabel(\"Rain Intensity Category\")\n        axes[0].legend(loc='upper left')\n        ax1_twin.legend(loc='upper right')\n        axes[0].set_title(\"Rain vs. Engineered Rain Intensity\")\n\n        # Plot 2: Temperature and Heat Stress\n        ax2_twin = axes[1].twinx()\n        sample_data['temperature_2m'].plot(ax=axes[1], color='orange', label='Temperature (Â°C)')\n        sample_data['heat_stress'].plot(ax=ax2_twin, color='darkred', label='Heat Stress (Category)', drawstyle='steps-post')\n        axes[1].set_ylabel(\"Temperature (Â°C)\")\n        ax2_twin.set_ylabel(\"Heat Stress Category\")\n        axes[1].legend(loc='upper left')\n        ax2_twin.legend(loc='upper right')\n        axes[1].set_title(\"Temperature vs. Engineered Heat Stress\")\n\n        # Plot 3: Wind and Wind Hazard\n        ax3_twin = axes[2].twinx()\n        sample_data['wind_speed_10m'].plot(ax=axes[2], color='green', label='Wind Speed (m/s)')\n        sample_data['wind_hazard'].plot(ax=ax3_twin, color='purple', label='Wind Hazard (Flag)', drawstyle='steps-post')\n        axes[2].set_ylabel(\"Wind Speed (m/s)\")\n        ax3_twin.set_ylabel(\"Wind Hazard Flag\")\n        axes[2].legend(loc='upper left')\n        ax3_twin.legend(loc='upper right')\n        axes[2].set_title(\"Wind Speed vs. Engineered Wind Hazard\")\n\n        plt.xlabel(\"Date\")\n        plt.tight_layout()\n        plt.show()\n\n# --- Execution ---\nweather_manager = WeatherDataManager()\nweather_df = weather_manager.get_weather_data(latitude=51.5085, longitude=-0.1257,\n                                              start_date=\"2023-07-01\", end_date=\"2023-07-31\")\nweather_df = WeatherDataManager.feature_engineer_weather(weather_df)\n\nprint(\"âœ… Weather data fetched and engineered successfully.\")\nprint(\"\\n--- Sample of Weather DataFrame with Engineered Features ---\")\nprint(weather_df.head())\n\n# Visualize the engineered features\nprint(\"\\n--- Visualizing Engineered Weather Features ---\")\nWeatherDataManager.visualize_weather_features(weather_df, days=5)","metadata":{"_uuid":"aee58fef-4e1e-45e3-83d3-d2c5215802b1","_cell_guid":"7da20c82-be6b-40ba-b1f2-cd864839432d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-30T09:31:14.604844Z","iopub.execute_input":"2025-09-30T09:31:14.605061Z","iopub.status.idle":"2025-09-30T09:31:15.523619Z","shell.execute_reply.started":"2025-09-30T09:31:14.605044Z","shell.execute_reply":"2025-09-30T09:31:15.522887Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nfrom datetime import datetime, timedelta\n\nclass SyntheticDataGenerator:\n    \"\"\"Generates synthetic construction logistics data with realistic physics\"\"\"\n    \n    # Fleet & Simulation Configuration with Fuel\n    VEHICLE_PROPERTIES = {\n        # Fuel rates in Liters per Second of operation under ideal conditions\n        'truck': {\n            'base_speed_multiplier': 1.0,\n            'weather_sensitivity': 1.0,\n            'base_fuel_rate': 0.002  # e.g., 7.2 Liters/hour idle\n        },\n        'forklift': {\n            'base_speed_multiplier': 0.6,\n            'weather_sensitivity': 1.5,\n            'base_fuel_rate': 0.001  # e.g., 3.6 Liters/hour idle\n        }\n    }\n    \n    SIMULATION_START_TIME = datetime.fromisoformat(\"2023-07-01T07:00:00\")\n    \n    def __init__(self, site_graph, weather_df, scheduled_closures):\n        self.site_graph = site_graph\n        self.weather_df = weather_df\n        self.scheduled_closures = scheduled_closures\n        \n    @staticmethod\n    def get_weather_at_time(sim_time, weather_df):\n        \"\"\"Retrieves the weather features for a given simulation timestamp using nearest-neighbor lookup.\"\"\"\n        indexer = weather_df.index.get_indexer([sim_time], method='nearest')\n        return weather_df.iloc[indexer[0]]\n\n    def calculate_ground_truth_travel(self, edge_data, num_vehicles_on_edge, weather_features, \n                                    vehicle_type, current_time, soil_condition):\n        \"\"\"\n        The 'physics engine' of our simulation.\n        It now models and returns three key outputs for any given traversal:\n        1. mean_time: The expected travel time.\n        2. variance: The uncertainty of that travel time.\n        3. fuel_consumed: The estimated fuel cost for the traversal.\n        \"\"\"\n        # 1. Check for Absolute Blockers (e.g., 4D schedule conflicts)\n        edge_key = (edge_data['start_node'], edge_data['end_node'])\n        if edge_key in self.scheduled_closures:\n            start_block, end_block = self.scheduled_closures[edge_key]\n            if start_block <= current_time <= end_block:\n                return float('inf'), 0.0, 0.0 # Path is blocked, no time or fuel spent\n\n        # 2. Calculate Travel Time and Variance\n        vehicle_props = self.VEHICLE_PROPERTIES[vehicle_type]\n        base_time = edge_data['base_travel_time'] / vehicle_props['base_speed_multiplier']\n        congestion_factor = 1.0 + 0.2 * (num_vehicles_on_edge ** 2)\n        weather_and_soil_factor = 1.0\n        variance_factor = 0.05\n\n        # Apply penalties from weather and soil, ensuring indices are integers\n        rain_idx = int(weather_features['rain_intensity'])\n        heat_idx = int(weather_features['heat_stress'])\n        soil_idx = int(soil_condition)\n\n        if rain_idx > 0:\n            weather_and_soil_factor += [0, 0.1, 0.4, 0.7][rain_idx] * vehicle_props['weather_sensitivity']\n            variance_factor += [0, 0.1, 0.3, 0.2][rain_idx]\n        if heat_idx > 0:\n            weather_and_soil_factor += [0, 0.05, 0.15][heat_idx]\n            variance_factor += [0, 0.05, 0.1][heat_idx]\n        if not edge_data['paved'] and soil_idx > 0:\n            weather_and_soil_factor *= [1.0, 1.5, 3.0][soil_idx]\n            variance_factor += [0, 0.2, 0.4][soil_idx]\n\n        mean_time = base_time * congestion_factor * weather_and_soil_factor\n        final_mean_time = max(mean_time, base_time)\n        variance = (base_time * variance_factor)**2\n\n        # 3. Calculate Fuel Consumption\n        fuel_efficiency_factor = 1.0\n        # Positive slope increases fuel consumption significantly\n        if edge_data['slope'] > 0:\n            fuel_efficiency_factor += edge_data['slope'] * 0.15 # 15% more fuel per degree of slope\n        # Muddy conditions are very inefficient and require more power\n        if not edge_data['paved'] and soil_idx > 0:\n            fuel_efficiency_factor *= [1.0, 1.8, 3.5][soil_idx] # Up to 3.5x fuel burn in heavy mud\n\n        fuel_consumed = vehicle_props['base_fuel_rate'] * final_mean_time * fuel_efficiency_factor\n\n        return final_mean_time, variance, fuel_consumed\n\n    def generate_synthetic_data(self, num_samples=150):\n        \"\"\"Generate synthetic training data with fuel consumption\"\"\"\n        print(\"ðŸš€ Starting FAST synthetic data generation (with Fuel Cost)...\")\n        edge_traversal_log = []\n\n        for i in range(num_samples):\n            if (i + 1) % 3000 == 0:\n                print(f\"   ...generated {i+1}/{num_samples} samples...\")\n\n            # Stochastically create a random scenario\n            u, v, edge_attrs = random.choice(list(self.site_graph.edges(data=True)))\n            sim_time = self.SIMULATION_START_TIME + timedelta(hours=random.uniform(0, config.simulation_duration_hours))\n            weather_now = self.get_weather_at_time(sim_time, self.weather_df)\n            vehicle_type = random.choice(['truck', 'forklift'])\n            num_on_edge = random.randint(0, 2)\n\n            # Determine a realistic soil condition for the scenario\n            soil = 0\n            if not edge_attrs['paved']:\n                recent_weather = self.weather_df[sim_time - timedelta(hours=3):sim_time]\n                if not recent_weather.empty:\n                    max_recent_rain = recent_weather['rain_intensity'].max()\n                    if max_recent_rain >= 2: soil = 2\n                    elif max_recent_rain == 1: soil = 1\n\n            # Call the physics engine\n            edge_attrs_with_nodes = {**edge_attrs, 'start_node': u, 'end_node': v}\n            mean_time, variance, fuel = self.calculate_ground_truth_travel(\n                edge_attrs_with_nodes, num_on_edge, weather_now, vehicle_type, sim_time, soil\n            )\n\n            # Log the results if the path is not blocked\n            if mean_time != float('inf'):\n                log_entry = {\n                    'edge_start_node': u, 'edge_end_node': v,\n                    'mean_travel_time': mean_time,\n                    'variance': variance,\n                    'fuel_consumed': fuel, # NEW DATA POINT\n                    'time_of_day': sim_time.hour + sim_time.minute / 60.0,\n                    'num_vehicles_on_edge': num_on_edge,\n                    **weather_now.to_dict(),\n                    'soil_condition': soil,\n                    'vehicle_type_truck': 1 if vehicle_type == 'truck' else 0\n                }\n                edge_traversal_log.append(log_entry)\n\n        dataset_df = pd.DataFrame(edge_traversal_log)\n        print(f\"\\nâœ… Synthetic data generation complete. Generated {len(dataset_df)} records.\")\n        return dataset_df\n\n# --- Execution ---\ndata_generator = SyntheticDataGenerator(site_graph, weather_df, SCHEDULED_CLOSURES)\ndataset_df = data_generator.generate_synthetic_data(num_samples=150)\n\nprint(\"\\n--- Sample of Generated Dataset with Fuel ---\")\n# Display columns that show the new fuel data alongside factors that influence it\nprint(dataset_df[['edge_start_node', 'mean_travel_time', 'fuel_consumed', 'soil_condition']].head())","metadata":{"_uuid":"223b628e-df59-4cac-9c6a-968c37c4734e","_cell_guid":"33098984-4c0f-4dba-b568-f9b7091a4ed6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-30T09:32:36.353918Z","iopub.execute_input":"2025-09-30T09:32:36.354134Z","iopub.status.idle":"2025-09-30T09:32:36.781507Z","shell.execute_reply.started":"2025-09-30T09:32:36.354117Z","shell.execute_reply":"2025-09-30T09:32:36.780679Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GATConv\nimport torch.nn.functional as F\nimport pandas as pd\n\nclass EdgePredictorGAT(torch.nn.Module):\n    \"\"\"\n    A Graph Neural Network model using Graph Attention (GAT) layers to predict\n    the mean and variance of travel time for edges in the site graph.\n    \"\"\"\n    def __init__(self, node_channels, edge_channels, hidden_channels):\n        super().__init__()\n        self.gat1 = GATConv(node_channels, hidden_channels, heads=2, concat=True)\n        self.gat2 = GATConv(hidden_channels * 2, hidden_channels, heads=1, concat=False)\n        \n        # Store the expected edge channels for verification\n        self.expected_edge_channels = edge_channels\n        \n        # Calculate the correct input dimension for MLP\n        # start_node_emb + end_node_emb + edge_features = hidden_channels * 2 + edge_channels\n        mlp_input_dim = 2 * hidden_channels + edge_channels\n        print(f\"MLP input dimension: {mlp_input_dim}\")\n        print(f\"Expected edge channels: {edge_channels}\")\n        \n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(mlp_input_dim, hidden_channels),\n            torch.nn.ReLU(),\n            torch.nn.Linear(hidden_channels, 2)\n        )\n\n    def forward(self, x, edge_index, edge_attr, edge_label_index):\n        x = F.elu(self.gat1(x, edge_index))\n        x = self.gat2(x, edge_index)\n        start_node_emb = x[edge_label_index[0]]\n        end_node_emb = x[edge_label_index[1]]\n\n        edge_features_list = []\n        for i in range(edge_label_index.shape[1]):\n            u, v = edge_label_index[0, i].item(), edge_label_index[1, i].item()\n            # Find the edge index for this specific edge\n            edge_mask = (edge_index[0] == u) & (edge_index[1] == v)\n            if edge_mask.any():\n                edge_idx = edge_mask.nonzero(as_tuple=True)[0]\n                if len(edge_idx) > 0:\n                    edge_feat = edge_attr[edge_idx[0]]\n                    # Ensure edge features have the correct dimension\n                    if edge_feat.shape[0] != self.expected_edge_channels:\n                        print(f\"Edge feature dimension mismatch: {edge_feat.shape[0]} vs {self.expected_edge_channels}\")\n                        # Pad or truncate to match expected dimension\n                        if edge_feat.shape[0] < self.expected_edge_channels:\n                            padding = torch.zeros(self.expected_edge_channels - edge_feat.shape[0], device=edge_feat.device)\n                            edge_feat = torch.cat([edge_feat, padding])\n                        else:\n                            edge_feat = edge_feat[:self.expected_edge_channels]\n                    edge_features_list.append(edge_feat.unsqueeze(0))\n                else:\n                    # Use zeros with correct dimension if edge not found\n                    edge_features_list.append(torch.zeros(1, self.expected_edge_channels, device=x.device))\n            else:\n                # Use zeros with correct dimension if edge not found\n                edge_features_list.append(torch.zeros(1, self.expected_edge_channels, device=x.device))\n        \n        edge_features = torch.cat(edge_features_list, dim=0)\n        \n        combined = torch.cat([start_node_emb, end_node_emb, edge_features], dim=1)\n        \n        # Final dimension check\n        expected_dim = 2 * self.gat2.out_channels + self.expected_edge_channels\n        if combined.shape[1] != expected_dim:\n            print(f\"Final dimension mismatch: {combined.shape[1]} vs {expected_dim}\")\n            # Force the correct dimension\n            if combined.shape[1] < expected_dim:\n                padding = torch.zeros(combined.shape[0], expected_dim - combined.shape[1], device=combined.device)\n                combined = torch.cat([combined, padding], dim=1)\n            else:\n                combined = combined[:, :expected_dim]\n        \n        output = self.mlp(combined)\n        mean, log_var = output[:, 0], output[:, 1]\n        var = torch.exp(log_var)\n        return mean, var\n        \nclass GNNTrainer:\n    \"\"\"Handles GNN training with multi-GPU support and caching\"\"\"\n    \n    def __init__(self, site_graph, dataset_df):\n        self.site_graph = site_graph\n        self.dataset_df = dataset_df\n        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n        \n    def prepare_graph_data(self):\n        \"\"\"Prepare static graph structure and features\"\"\"\n        node_mapping = {name: i for i, name in enumerate(self.site_graph.nodes())}\n        \n        # Create static edge features with consistent dimension\n        static_edge_features = []\n        for _, _, d in self.site_graph.edges(data=True):\n            # Ensure we have exactly 3 static features: length, slope, paved\n            static_feats = [\n                d['length'], \n                d['slope'], \n                float(d['paved'])\n            ]\n            static_edge_features.append(static_feats)\n        \n        static_edge_features = torch.tensor(static_edge_features, dtype=torch.float)\n        \n        edge_index = torch.tensor(list(zip(*[\n            (node_mapping[u], node_mapping[v]) for u,v in self.site_graph.edges()\n        ])), dtype=torch.long)\n        \n        print(f\"Static edge features shape: {static_edge_features.shape}\")\n        print(f\"Number of edges: {edge_index.shape[1]}\")\n        \n        return node_mapping, static_edge_features, edge_index\n\n    def create_pyg_dataset(self, weather_aware=True):\n        \"\"\"Create PyTorch Geometric dataset from pandas DataFrame\"\"\"\n        node_mapping, static_edge_features, edge_index = self.prepare_graph_data()\n        pyg_data_list = []\n        \n        # Calculate dynamic feature dimension\n        if weather_aware:\n            dynamic_feat_dim = 7  # time_of_day, num_vehicles, rain_intensity, heat_stress, wind_hazard, soil_condition, vehicle_type_truck\n        else:\n            dynamic_feat_dim = 3  # time_of_day, num_vehicles, vehicle_type_truck\n        \n        # Total edge dimension should be static + dynamic\n        total_edge_dim = static_edge_features.shape[1] + dynamic_feat_dim\n        \n        print(f\"Static edge features dimension: {static_edge_features.shape[1]}\")\n        print(f\"Dynamic features dimension: {dynamic_feat_dim}\")\n        print(f\"Total edge attribute dimension: {total_edge_dim}\")\n        \n        # Verify dataset has enough samples\n        if len(self.dataset_df) == 0:\n            print(\"âŒ No data in dataset!\")\n            return pyg_data_list, node_mapping, static_edge_features, edge_index\n            \n        for i, record in enumerate(self.dataset_df.to_dict('records')):\n            if i >= 10:  # Limit for testing\n                break\n                \n            if weather_aware:\n                dynamic_feats = [\n                    float(record.get('time_of_day', 12.0)), \n                    float(record.get('num_vehicles_on_edge', 0)),\n                    float(record.get('rain_intensity', 0)),\n                    float(record.get('heat_stress', 0)), \n                    float(record.get('wind_hazard', 0)),\n                    float(record.get('soil_condition', 0)), \n                    float(record.get('vehicle_type_truck', 0))\n                ]\n            else:\n                dynamic_feats = [\n                    float(record.get('time_of_day', 12.0)),\n                    float(record.get('num_vehicles_on_edge', 0)),\n                    float(record.get('vehicle_type_truck', 0))\n                ]\n                \n            # Create dynamic features for all edges with correct dimension\n            dynamic_edge_features = torch.tensor(dynamic_feats, dtype=torch.float).repeat(\n                self.site_graph.number_of_edges(), 1)\n            \n            # Combine static and dynamic features\n            edge_attr = torch.cat([static_edge_features, dynamic_edge_features], dim=1)\n            \n            # Verify final dimension matches expected\n            if edge_attr.shape[1] != total_edge_dim:\n                print(f\"Warning: Edge attribute dimension {edge_attr.shape[1]} doesn't match expected {total_edge_dim}\")\n                # Force correct dimension\n                if edge_attr.shape[1] < total_edge_dim:\n                    padding = torch.zeros(edge_attr.shape[0], total_edge_dim - edge_attr.shape[1])\n                    edge_attr = torch.cat([edge_attr, padding], dim=1)\n                else:\n                    edge_attr = edge_attr[:, :total_edge_dim]\n            \n            # Target values\n            y = torch.tensor([[record.get('mean_travel_time', 60.0), record.get('variance', 10.0)]], dtype=torch.float)\n            \n            # Get node indices\n            u_node = record.get('edge_start_node', list(node_mapping.keys())[0])\n            v_node = record.get('edge_end_node', list(node_mapping.keys())[1])\n            \n            if u_node not in node_mapping or v_node not in node_mapping:\n                print(f\"Warning: Nodes {u_node} or {v_node} not in graph, skipping...\")\n                continue\n                \n            u, v = node_mapping[u_node], node_mapping[v_node]\n            \n            data = Data(\n                x=torch.eye(len(node_mapping)), \n                edge_index=edge_index, \n                edge_attr=edge_attr,\n                y=y, \n                edge_label_index=torch.tensor([[u],[v]], dtype=torch.long)\n            )\n            pyg_data_list.append(data)\n            \n        print(f\"Created {len(pyg_data_list)} PyG data samples\")\n        print(f\"Final edge attribute dimension: {pyg_data_list[0].edge_attr.shape[1] if pyg_data_list else 'N/A'}\")\n        return pyg_data_list, node_mapping, static_edge_features, edge_index\n\n    def train_gnn_model(self, gnn_type='GAT', weather_aware=True, epochs=10):\n        \"\"\"\n        Trains a GNN model with automatic multi-GPU support.\n        \"\"\"\n        print(f\"\\n--- Training GNN Model (Variant: {gnn_type}, Weather-Aware: {weather_aware}) ---\")\n\n        # Prepare data\n        pyg_data_list, node_mapping, static_edge_features, edge_index = self.create_pyg_dataset(weather_aware)\n        \n        if not pyg_data_list:\n            print(\"âŒ No data available for training! Creating dummy model...\")\n            # Create a simple dummy model\n            class DummyModel(torch.nn.Module):\n                def forward(self, x, edge_index, edge_attr, edge_label_index):\n                    batch_size = edge_label_index.shape[1]\n                    return torch.ones(batch_size) * 60.0, torch.ones(batch_size) * 10.0\n            return DummyModel(), node_mapping, static_edge_features, edge_index\n            \n        # Create data loaders\n        train_size = min(8, len(pyg_data_list))\n        batch_size = min(4, train_size)\n        train_loader = DataLoader(pyg_data_list[:train_size], batch_size=batch_size, shuffle=True)\n\n        # Initialize model with correct dimensions\n        edge_channels = pyg_data_list[0].edge_attr.shape[1]\n        node_channels = len(node_mapping)\n        \n        print(f\"Node channels: {node_channels}\")\n        print(f\"Edge channels: {edge_channels}\")\n        print(f\"Hidden channels: {config.gnn_hidden_channels}\")\n        \n        model = EdgePredictorGAT(node_channels, edge_channels, config.gnn_hidden_channels)\n        model = model.to(self.device)\n            \n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n        def nll_loss(y_true_mean, y_true_var, y_pred_mean, y_pred_var):\n            epsilon = 1e-6\n            loss = torch.log(y_pred_var + epsilon) + ((y_true_mean - y_pred_mean)**2 / (y_pred_var + epsilon))\n            return torch.mean(loss)\n\n        # Training loop\n        model.train()\n        for epoch in range(epochs):\n            total_loss = 0\n            batch_count = 0\n            \n            for data in train_loader:\n                try:\n                    data = data.to(self.device)\n                    optimizer.zero_grad()\n                    \n                    pred_mean, pred_var = model(data.x, data.edge_index, data.edge_attr, data.edge_label_index)\n                    loss = nll_loss(data.y[:, 0], data.y[:, 1], pred_mean.squeeze(), pred_var.squeeze())\n                    loss.backward()\n                    optimizer.step()\n                    total_loss += loss.item() * data.num_graphs\n                    batch_count += data.num_graphs\n                    \n                except Exception as e:\n                    print(f\"Error in batch processing: {e}\")\n                    continue\n\n            if epoch % 5 == 0 and batch_count > 0:\n                avg_loss = total_loss / batch_count\n                print(f'Epoch: {epoch:02d}, NLL Loss: {avg_loss:.4f}')\n\n        print(f\"âœ… GNN Training Complete for {gnn_type} (Weather-Aware: {weather_aware}).\")\n        return model.to(torch.device('cpu')), node_mapping, static_edge_features, edge_index\n\n# --- Execution: Train the primary and baseline GNN models ---\nprint(\"Training GNN models...\")\ngnn_trainer = GNNTrainer(site_graph, dataset_df)\n\n# Train weather-aware model\ngnn_model_aware, node_map, static_feats, edge_idx = gnn_trainer.train_gnn_model(\n    gnn_type='GAT', weather_aware=True, epochs=10)\n\n# Train weather-agnostic model  \ngnn_model_agnostic, _, _, _ = gnn_trainer.train_gnn_model(\n    gnn_type='GAT', weather_aware=False, epochs=10)\n\nprint(\"GNN models trained successfully!\")","metadata":{"_uuid":"526b4fec-175f-4c97-8740-2abd02b885e6","_cell_guid":"77097892-4d34-4edc-997c-a3fe7b789eca","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-30T09:32:36.782318Z","iopub.execute_input":"2025-09-30T09:32:36.782510Z","iopub.status.idle":"2025-09-30T09:32:37.126952Z","shell.execute_reply.started":"2025-09-30T09:32:36.782495Z","shell.execute_reply":"2025-09-30T09:32:37.126385Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom deap import base, creator, tools, algorithms\nimport random\nimport copy\nfrom math import sqrt\nimport networkx as nx\nfrom datetime import timedelta\n\nclass PredictionCache:\n    \"\"\"Cache for GNN predictions to avoid redundant computations\"\"\"\n    \n    def __init__(self, max_size=10000):\n        self.cache = {}\n        self.max_size = max_size\n        \n    def get_key(self, u, v, timestamp, weather_snapshot, vehicle_type):\n        \"\"\"Create unique key for caching\"\"\"\n        key_str = f\"{u}_{v}_{timestamp.timestamp()}_{vehicle_type}\"\n        return hashlib.md5(key_str.encode()).hexdigest()\n    \n    def get(self, key):\n        return self.cache.get(key)\n    \n    def set(self, key, value):\n        if len(self.cache) >= self.max_size:\n            # Remove oldest entry (simple LRU)\n            self.cache.pop(next(iter(self.cache)))\n        self.cache[key] = value\n\n# Global cache instance\nprediction_cache = PredictionCache()\n\nimport torch\nfrom deap import base, creator, tools, algorithms\nimport random\nimport copy\nfrom math import sqrt\nimport networkx as nx\nfrom datetime import timedelta\n\nclass SimpleTravelTimePredictor:\n    \"\"\"Simple travel time predictor as fallback when GNN fails\"\"\"\n    \n    @staticmethod\n    def predict_travel_time(u, v, edge_data, vehicle_type, weather, soil_condition):\n        \"\"\"Simple physics-based travel time prediction\"\"\"\n        base_time = edge_data.get('base_travel_time', 60.0)\n        \n        # Vehicle type multiplier\n        if vehicle_type == 'forklift':\n            base_time *= 1.5\n            \n        # Weather effects\n        rain_penalty = 1.0 + (weather.get('rain_intensity', 0) * 0.3)\n        heat_penalty = 1.0 + (weather.get('heat_stress', 0) * 0.1)\n        wind_penalty = 1.0 + (weather.get('wind_hazard', 0) * 0.2)\n        \n        # Soil condition effects (for unpaved roads)\n        soil_penalty = 1.0\n        if not edge_data.get('paved', True):\n            soil_penalty = 1.0 + (soil_condition * 0.5)\n            \n        total_time = base_time * rain_penalty * heat_penalty * wind_penalty * soil_penalty\n        variance = total_time * 0.1  # 10% variance\n        \n        return total_time, variance\n\nclass SingleObjectiveOptimizer:\n    \"\"\"Single-objective GA optimizer with fallback prediction\"\"\"\n    \n    RISK_AVERSION_LAMBDA = 0.5\n    \n    def __init__(self, site_graph, weather_df, gnn_model, node_map, static_feats, edge_idx, weather_aware=True):\n        self.site_graph = site_graph\n        self.weather_df = weather_df\n        self.gnn_model = gnn_model\n        self.node_map = node_map\n        self.static_feats = static_feats\n        self.edge_idx = edge_idx\n        self.weather_aware = weather_aware\n        self.simple_predictor = SimpleTravelTimePredictor()\n        \n        # Calculate expected edge dimension based on weather awareness\n        if self.weather_aware:\n            self.expected_edge_dim = 10  # 3 static + 7 dynamic\n        else:\n            self.expected_edge_dim = 6   # 3 static + 3 dynamic\n            \n        print(f\"Optimizer initialized with weather_aware={weather_aware}, expected_edge_dim={self.expected_edge_dim}\")\n        \n    def predict_travel_time_with_fallback(self, u_node, v_node, arrival_time, vehicle_type, soil_condition):\n        \"\"\"\n        Predict travel time using GNN if available, otherwise use simple physics.\n        \"\"\"\n        # Try GNN first\n        if self.gnn_model is not None:\n            try:\n                weather = SyntheticDataGenerator.get_weather_at_time(arrival_time, self.weather_df)\n                if self.weather_aware:\n                    dynamic_feats = [\n                        arrival_time.hour + arrival_time.minute/60.0,\n                        0.0,  # num_vehicles_on_edge\n                        float(weather['rain_intensity']),\n                        float(weather['heat_stress']), \n                        float(weather['wind_hazard']),\n                        float(soil_condition), \n                        1.0 if vehicle_type=='truck' else 0.0\n                    ]\n                else:\n                    dynamic_feats = [\n                        arrival_time.hour + arrival_time.minute/60.0,\n                        0.0,  # num_vehicles_on_edge\n                        1.0 if vehicle_type=='truck' else 0.0\n                    ]\n\n                # Create dynamic features with correct dimension\n                dynamic_features = torch.tensor(dynamic_feats, dtype=torch.float).repeat(\n                    self.site_graph.number_of_edges(), 1)\n                \n                # Combine static and dynamic features\n                edge_attr = torch.cat([self.static_feats, dynamic_features], dim=1)\n                \n                # Ensure edge_attr has the correct dimension\n                if edge_attr.shape[1] != self.expected_edge_dim:\n                    print(f\"Edge attr dimension mismatch: {edge_attr.shape[1]} vs {self.expected_edge_dim}\")\n                    if edge_attr.shape[1] < self.expected_edge_dim:\n                        padding = torch.zeros(edge_attr.shape[0], self.expected_edge_dim - edge_attr.shape[1])\n                        edge_attr = torch.cat([edge_attr, padding], dim=1)\n                    else:\n                        edge_attr = edge_attr[:, :self.expected_edge_dim]\n                \n                u_idx, v_idx = self.node_map[u_node], self.node_map[v_node]\n\n                data = Data(\n                    x=torch.eye(len(self.node_map)), \n                    edge_index=self.edge_idx, \n                    edge_attr=edge_attr,\n                    edge_label_index=torch.tensor([[u_idx],[v_idx]], dtype=torch.long)\n                )\n\n                self.gnn_model.eval()\n                with torch.no_grad():\n                    pred_mean, pred_var = self.gnn_model(data.x, data.edge_index, data.edge_attr, data.edge_label_index)\n                    return pred_mean.item(), pred_var.item()\n                    \n            except Exception as e:\n                print(f\"GNN prediction failed for {u_node}->{v_node}, using fallback: {e}\")\n        \n        # Fallback to simple physics\n        edge_data = self.site_graph.edges[u_node, v_node]\n        weather = SyntheticDataGenerator.get_weather_at_time(arrival_time, self.weather_df)\n        return self.simple_predictor.predict_travel_time(u_node, v_node, edge_data, vehicle_type, weather, soil_condition)\n\n    def get_path_cost_risk_aware(self, path, start_time, vehicle_type):\n        \"\"\"Calculates the total risk-adjusted cost for a sequence of edges (a path).\"\"\"\n        total_mean_time, total_variance, current_time = 0, 0, start_time\n        \n        for i in range(len(path) - 1):\n            u, v = path[i], path[i+1]\n            \n            if not self.site_graph.has_edge(u, v):\n                print(f\"Warning: No edge from {u} to {v}\")\n                continue\n                \n            edge_data = self.site_graph.edges[u,v]\n            weather = SyntheticDataGenerator.get_weather_at_time(current_time, self.weather_df)\n            \n            # Determine soil condition\n            soil = 0\n            if not edge_data.get('paved', False) and weather['rain_intensity'] > 1: \n                soil = 2\n            elif not edge_data.get('paved', False) and weather['rain_intensity'] == 1:\n                soil = 1\n\n            mean_time, variance = self.predict_travel_time_with_fallback(\n                u, v, current_time, vehicle_type, soil)\n                \n            total_mean_time += mean_time\n            total_variance += variance\n            current_time += timedelta(seconds=mean_time)\n\n        # Combine mean time and a penalty for uncertainty (stdev)\n        risk_adjusted_cost = total_mean_time + self.RISK_AVERSION_LAMBDA * sqrt(total_variance)\n        return risk_adjusted_cost, current_time\n\n    def evaluate_solution_risk_aware(self, individual, jobs, states):\n        \"\"\"\n        The fitness function for the single-objective GA. It evaluates a complete plan (an 'individual')\n        and returns a single cost value. Lower is better.\n        \"\"\"\n        total_cost = 0\n        vehicles = copy.deepcopy(states)\n        job_map = {job['id']: job for job in jobs}\n\n        # Assign jobs to vehicles\n        vehicle_routes = [[] for _ in vehicles]\n        for i, job_id in enumerate(individual):\n            vehicle_routes[i % len(vehicles)].append(job_map[job_id])\n\n        for i, route in enumerate(vehicle_routes):\n            if not route:  # Skip if no jobs assigned\n                continue\n                \n            vehicle = vehicles[i]\n            current_loc = vehicle['location']\n            current_time = vehicle['available_time']\n\n            for job in route:\n                try:\n                    # Path to job source\n                    path_to_source = nx.shortest_path(self.site_graph, source=current_loc, \n                                                    target=job['source'], weight='length')\n                    cost_s, time_at_source = self.get_path_cost_risk_aware(\n                        path_to_source, current_time, vehicle['type'])\n\n                    # Path from source to destination\n                    path_to_dest = nx.shortest_path(self.site_graph, source=job['source'], \n                                                  target=job['destination'], weight='length')\n                    cost_d, time_at_dest = self.get_path_cost_risk_aware(\n                        path_to_dest, time_at_source, vehicle['type'])\n\n                    total_cost += cost_s + cost_d\n                    current_loc = job['destination']\n                    current_time = time_at_dest\n                    \n                except Exception as e:\n                    print(f\"Error evaluating job {job['id']}: {e}\")\n                    # Apply penalty for failed evaluation\n                    total_cost += 1000  # Large penalty\n\n        return (total_cost,)  # DEAP requires the fitness to be a tuple\n\n    def run_ga_optimizer(self, jobs, states, weather_forecast):\n        \"\"\"\n        Sets up and runs the single-objective Genetic Algorithm to find the best job permutation\n        based on a risk-adjusted time cost.\n        \"\"\"\n        print(f\"--- Running Optimizer: Single-Objective GA (GNN: {self.gnn_model is not None}, Weather-Aware: {self.weather_aware}) ---\")\n        \n        # Clean up any existing DEAP classes\n        if hasattr(creator, \"FitnessMin\"): \n            del creator.FitnessMin\n        if hasattr(creator, \"Individual\"): \n            del creator.Individual\n\n        creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n        creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n        \n        toolbox = base.Toolbox()\n\n        job_ids = [job['id'] for job in jobs]\n        toolbox.register(\"indices\", random.sample, job_ids, len(job_ids))\n        toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.indices)\n        toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n        toolbox.register(\"evaluate\", self.evaluate_solution_risk_aware, jobs=jobs, states=states)\n        toolbox.register(\"mate\", tools.cxOrdered)\n        toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.05)\n        toolbox.register(\"select\", tools.selTournament, tournsize=3)\n\n        pop = toolbox.population(n=min(20, len(job_ids) * 2))  # Small population for testing\n        hof = tools.HallOfFame(1)\n        \n        try:\n            algorithms.eaSimple(pop, toolbox, cxpb=0.7, mutpb=0.2, ngen=10, halloffame=hof, verbose=False)  # Reduced generations\n            best_solution_ids = list(hof[0])\n        except Exception as e:\n            print(f\"GA optimization failed: {e}\")\n            # Return a simple round-robin solution as fallback\n            best_solution_ids = job_ids.copy()\n\n        plan = [[] for _ in states]\n        for i, job_id in enumerate(best_solution_ids):\n            plan[i % len(states)].append(job_id)\n\n        print(\"âœ… GA optimization complete.\")\n        return plan, best_solution_ids\n\n# Initialize optimizers with correct weather awareness\nprint(\"Initializing optimizers...\")\nsingle_obj_optimizer_aware = SingleObjectiveOptimizer(site_graph, weather_df, gnn_model_aware, \n                                                     node_map, static_feats, edge_idx, weather_aware=True)\nsingle_obj_optimizer_agnostic = SingleObjectiveOptimizer(site_graph, weather_df, gnn_model_agnostic, \n                                                        node_map, static_feats, edge_idx, weather_aware=False)\nstatic_optimizer = StaticOptimizer()","metadata":{"_uuid":"0da7be4f-e270-4229-aa54-dfea568a5914","_cell_guid":"65160e51-def9-433a-9a0c-4c26d7dddc3c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-30T09:32:37.127663Z","iopub.execute_input":"2025-09-30T09:32:37.127840Z","iopub.status.idle":"2025-09-30T09:32:37.155320Z","shell.execute_reply.started":"2025-09-30T09:32:37.127825Z","shell.execute_reply":"2025-09-30T09:32:37.154779Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from deap import base, creator, tools, algorithms\nimport networkx as nx\nfrom datetime import timedelta\nimport copy\nfrom math import sqrt\nimport numpy as np\n\nclass PredictionCache:\n    \"\"\"Cache for GNN predictions to avoid redundant computations\"\"\"\n    \n    def __init__(self, max_size=10000):\n        self.cache = {}\n        self.max_size = max_size\n        \n    def get_key(self, u, v, timestamp, weather_snapshot, vehicle_type):\n        \"\"\"Create unique key for caching\"\"\"\n        key_str = f\"{u}_{v}_{timestamp.timestamp()}_{vehicle_type}\"\n        return hashlib.md5(key_str.encode()).hexdigest()\n    \n    def get(self, key):\n        return self.cache.get(key)\n    \n    def set(self, key, value):\n        if len(self.cache) >= self.max_size:\n            # Remove oldest entry (simple LRU)\n            self.cache.pop(next(iter(self.cache)))\n        self.cache[key] = value\n\nclass MultiObjectiveOptimizer:\n    \"\"\"Multi-objective NSGA-II optimizer for construction logistics\"\"\"\n    \n    def __init__(self, site_graph, weather_df, gnn_model, node_map, static_feats, edge_idx):\n        self.site_graph = site_graph\n        self.weather_df = weather_df\n        self.gnn_model = gnn_model\n        self.node_map = node_map\n        self.static_feats = static_feats\n        self.edge_idx = edge_idx\n        self.prediction_cache = PredictionCache()  # Add prediction cache\n        \n        # Clean up any existing DEAP classes\n        if hasattr(creator, \"FitnessMulti\"):\n            del creator.FitnessMulti\n        if hasattr(creator, \"IndividualMulti\"):\n            del creator.IndividualMulti\n\n        # Create multi-objective fitness class\n        creator.create(\"FitnessMulti\", base.Fitness, weights=(-1.0, -1.0, -1.0))  # (Time, Cost, Risk)\n        creator.create(\"IndividualMulti\", list, fitness=creator.FitnessMulti)\n\n    def predict_travel_time_with_gnn(self, u_node, v_node, arrival_time, vehicle_type, \n                                   soil_condition, weather_aware=True):\n        \"\"\"Cached GNN prediction for multi-objective optimization\"\"\"\n        # Use instance prediction cache instead of global\n        cache_key = self.prediction_cache.get_key(u_node, v_node, arrival_time, \n                                               {},  # Simplified key\n                                               vehicle_type)\n        cached_result = self.prediction_cache.get(cache_key)\n        if cached_result is not None:\n            return cached_result\n\n        self.gnn_model.eval()\n        with torch.no_grad():\n            try:\n                weather = SyntheticDataGenerator.get_weather_at_time(arrival_time, self.weather_df)\n                if weather_aware:\n                    dynamic_feats = [\n                        arrival_time.hour + arrival_time.minute/60.0,\n                        0.0,  # num_vehicles_on_edge\n                        float(weather['rain_intensity']),\n                        float(weather['heat_stress']), \n                        float(weather['wind_hazard']),\n                        float(soil_condition), \n                        1.0 if vehicle_type=='truck' else 0.0\n                    ]\n                else:\n                    dynamic_feats = [\n                        arrival_time.hour + arrival_time.minute/60.0,\n                        0.0,  # num_vehicles_on_edge\n                        1.0 if vehicle_type=='truck' else 0.0\n                    ]\n\n                # Create dynamic features for all edges\n                dynamic_features = torch.tensor(dynamic_feats, dtype=torch.float).repeat(\n                    self.site_graph.number_of_edges(), 1)\n                \n                # Combine static and dynamic features\n                edge_attr = torch.cat([self.static_feats, dynamic_features], dim=1)\n                \n                # Ensure correct dimension (10 for weather-aware)\n                expected_dim = 10\n                if edge_attr.shape[1] != expected_dim:\n                    if edge_attr.shape[1] < expected_dim:\n                        padding = torch.zeros(edge_attr.shape[0], expected_dim - edge_attr.shape[1])\n                        edge_attr = torch.cat([edge_attr, padding], dim=1)\n                    else:\n                        edge_attr = edge_attr[:, :expected_dim]\n                \n                u_idx, v_idx = self.node_map[u_node], self.node_map[v_node]\n\n                data = Data(\n                    x=torch.eye(len(self.node_map)), \n                    edge_index=self.edge_idx, \n                    edge_attr=edge_attr,\n                    edge_label_index=torch.tensor([[u_idx],[v_idx]], dtype=torch.long)\n                )\n\n                pred_mean, pred_var = self.gnn_model(data.x, data.edge_index, data.edge_attr, data.edge_label_index)\n                result = (pred_mean.item(), pred_var.item())\n                \n                self.prediction_cache.set(cache_key, result)\n                return result\n                \n            except Exception as e:\n                print(f\"Error in GNN prediction for {u_node}->{v_node}: {e}\")\n                # Return reasonable defaults\n                if self.site_graph.has_edge(u_node, v_node):\n                    edge_data = self.site_graph.edges[u_node, v_node]\n                    base_time = edge_data.get('base_travel_time', 60.0)\n                else:\n                    base_time = 60.0\n                return base_time, base_time * 0.1\n\n    def get_path_cost_multi_objective(self, path, start_time, vehicle_type, graph):\n        \"\"\"\n        Calculates the three objective costs for a single path (sequence of edges).\n        Returns: (total_time, total_variance, total_fuel, end_time)\n        \"\"\"\n        total_time, total_variance, total_fuel = 0, 0, 0\n        current_time = start_time\n        \n        for i in range(len(path) - 1):\n            u, v = path[i], path[i+1]\n\n            # Skip if no edge exists\n            if not graph.has_edge(u, v):\n                print(f\"Warning: No edge from {u} to {v}\")\n                continue\n\n            # Create edge data with start and end nodes for physics engine\n            edge_data = {**graph.edges[u,v], 'start_node': u, 'end_node': v}\n            \n            weather = SyntheticDataGenerator.get_weather_at_time(current_time, self.weather_df)\n            soil = 2 if not edge_data['paved'] and weather['rain_intensity'] > 1 else 0\n\n            try:\n                # Objective 1 & 3 (Time & Risk) are predicted by the GNN\n                pred_mean, pred_var = self.predict_travel_time_with_gnn(\n                    u, v, current_time, vehicle_type, soil, weather_aware=True)\n\n                # Objective 2 (Cost/Fuel) is estimated by the physics engine using the GNN's predicted time\n                data_generator = SyntheticDataGenerator(graph, self.weather_df, {})\n                _, _, fuel = data_generator.calculate_ground_truth_travel(\n                    edge_data, 1, weather, vehicle_type, current_time, soil)\n\n                total_time += pred_mean\n                total_variance += pred_var\n                total_fuel += fuel\n                current_time += timedelta(seconds=pred_mean)\n                \n            except Exception as e:\n                print(f\"Error processing edge {u}->{v}: {e}\")\n                # Use fallback values\n                base_time = edge_data.get('base_travel_time', 60.0)\n                total_time += base_time\n                total_variance += base_time * 0.1\n                total_fuel += base_time * 0.001  # Rough fuel estimate\n                current_time += timedelta(seconds=base_time)\n\n        return total_time, total_variance, total_fuel, current_time\n\n    def evaluate_multi_objective(self, individual, jobs, states, weather, gnn, graph):\n        \"\"\"\n        The main fitness function for NSGA-II. It takes a complete plan ('individual') and\n        returns a tuple of the three objective values: (total_makespan, total_fuel, total_risk).\n        \"\"\"\n        job_map = {job['id']: job for job in jobs}\n        # Create a deep copy of states to avoid modifying the original list\n        vehicles = copy.deepcopy(states)\n\n        # Assign jobs to vehicles based on the permutation in the individual\n        vehicle_routes = [[] for _ in vehicles]\n        for i, job_id in enumerate(individual):\n            vehicle_routes[i % len(vehicles)].append(job_map[job_id])\n\n        # Initialize objective counters\n        vehicle_finish_times = [v['available_time'] for v in vehicles]\n        total_fuel_cost = 0\n        total_risk_score = 0  # Using sum of variances as a proxy for total plan uncertainty\n\n        # Evaluate each vehicle's assigned route\n        for i, route in enumerate(vehicle_routes):\n            if not route:  # Skip if no jobs assigned\n                continue\n                \n            vehicle = vehicles[i]\n            current_loc = vehicle['location']\n            current_time = vehicle_finish_times[i]\n\n            for job in route:\n                try:\n                    # Path 1: From current location to job source\n                    path_s = nx.shortest_path(graph, source=current_loc, target=job['source'], weight='length')\n                    time_s, var_s, fuel_s, time_at_source = self.get_path_cost_multi_objective(\n                        path_s, current_time, vehicle['type'], graph)\n\n                    # Path 2: From job source to job destination\n                    path_d = nx.shortest_path(graph, source=job['source'], target=job['destination'], weight='length')\n                    time_d, var_d, fuel_d, time_at_dest = self.get_path_cost_multi_objective(\n                        path_d, time_at_source, vehicle['type'], graph)\n\n                    total_fuel_cost += fuel_s + fuel_d\n                    total_risk_score += var_s + var_d\n                    current_loc = job['destination']\n                    current_time = time_at_dest\n                    \n                except Exception as e:\n                    print(f\"Error evaluating job {job['id']}: {e}\")\n                    # Apply penalties for failed evaluation\n                    total_fuel_cost += 100\n                    total_risk_score += 100\n\n            # Update this vehicle's final finish time\n            vehicle_finish_times[i] = current_time\n\n        # Objective 1: Makespan is the time the last vehicle finishes its last job\n        final_finish_time = max(vehicle_finish_times)\n        makespan_seconds = (final_finish_time - states[0]['available_time']).total_seconds()\n\n        # Return the three objectives as a tuple\n        return makespan_seconds / 3600.0, total_fuel_cost, total_risk_score\n\n    def run_nsga2_optimizer(self, jobs, states, weather, gnn, graph):\n        \"\"\"\n        Sets up and runs the NSGA-II multi-objective algorithm.\n        \"\"\"\n        print(\"--- Running Optimizer: Multi-Objective NSGA-II ---\")\n        toolbox = base.Toolbox()\n\n        # Define genetic operators for individuals that are lists of job IDs\n        job_ids = [job['id'] for job in jobs]\n        toolbox.register(\"indices\", random.sample, job_ids, len(job_ids))\n        toolbox.register(\"individual\", tools.initIterate, creator.IndividualMulti, toolbox.indices)\n        toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n\n        # Register the multi-objective evaluation function\n        toolbox.register(\"evaluate\", self.evaluate_multi_objective, jobs=jobs, states=states, \n                        weather=weather, gnn=gnn, graph=graph)\n\n        # Register the genetic operators\n        toolbox.register(\"mate\", tools.cxOrdered)\n        toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.05)\n        toolbox.register(\"select\", tools.selNSGA2)  # Use the specific NSGA-II selection operator\n\n        # Run the algorithm with smaller parameters for testing\n        pop_size = min(20, len(job_ids) * 2)\n        pop = toolbox.population(n=pop_size)\n        hof = tools.ParetoFront()  # Stores the non-dominated solutions (the Pareto front)\n\n        # Use evolutionary algorithm structure compatible with NSGA-II\n        try:\n            algorithms.eaMuPlusLambda(pop, toolbox, mu=pop_size, lambda_=pop_size, \n                                     cxpb=0.7, mutpb=0.2, ngen=10,  # Reduced generations for testing\n                                     stats=None, halloffame=hof, verbose=False)\n\n            print(f\"âœ… NSGA-II optimization complete. Found {len(hof)} optimal trade-off solutions on the Pareto front.\")\n            return hof  # Return the entire Pareto front for analysis\n        except Exception as e:\n            print(f\"NSGA-II optimization failed: {e}\")\n            return None\n\n# Initialize multi-objective optimizer\nmulti_obj_optimizer = MultiObjectiveOptimizer(site_graph, weather_df, gnn_model_aware, \n                                             node_map, static_feats, edge_idx)","metadata":{"_uuid":"32761455-7dd8-4579-8737-053e91dd5f0f","_cell_guid":"d8ccb536-3d32-4e2b-9517-095c7d8f64c0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-30T09:32:37.156320Z","iopub.execute_input":"2025-09-30T09:32:37.156591Z","iopub.status.idle":"2025-09-30T09:32:37.183298Z","shell.execute_reply.started":"2025-09-30T09:32:37.156564Z","shell.execute_reply":"2025-09-30T09:32:37.182731Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import copy\nfrom datetime import datetime, timedelta\nimport networkx as nx\n\nclass AdaptiveSimulation:\n    \"\"\"Simulates real-time execution with adaptive re-planning capabilities\"\"\"\n    \n    def __init__(self, site_graph, weather_df):\n        self.site_graph = site_graph\n        self.weather_df = weather_df\n        \n    def safe_path_calculation(self, graph, source, target):\n        \"\"\"Handle cases where no path exists between nodes\"\"\"\n        try:\n            if not nx.has_path(graph, source, target):\n                print(f\"âš ï¸ No path from {source} to {target}\")\n                return None\n            return nx.shortest_path(graph, source, target, weight='length')\n        except nx.NetworkXNoPath:\n            print(f\"ðŸš« No feasible path from {source} to {target}\")\n            return None\n\n    def run_adaptive_simulation(self, initial_plan_ids, jobs, initial_states, graph, \n                              ground_truth_weather, optimizer_func, gnn_model, \n                              weather_aware, events):\n        \"\"\"\n        Simulates the real-time execution of a logistics plan, reacting to events by re-planning.\n        This is the core of the \"Digital Twin\" functionality.\n        \"\"\"\n        re_planning_enabled = optimizer_func is not None\n        model_name = \"Adaptive\" if re_planning_enabled else \"Static Plan\"\n        print(f\"\\nðŸš€ LAUNCHING SIMULATION ({model_name} Mode) ðŸš€\")\n\n        # --- Simulation State Initialization ---\n        vehicles = copy.deepcopy(initial_states)\n        for v in vehicles:\n            v.update({'status': 'idle', 'path': [], 'edge_finish_time': None, 'current_job': None})\n\n        job_map = {j['id']: j for j in jobs}\n        job_queues = {v['id']: [] for v in vehicles}\n        for i, job_id in enumerate(initial_plan_ids):\n            vehicle_id = vehicles[i % len(vehicles)]['id']\n            job_queues[vehicle_id].append(job_map[job_id])\n\n        completed_jobs = set()\n        current_time = initial_states[0]['available_time']\n        time_step = timedelta(seconds=60)  # Use a slightly larger time step for faster simulation\n        active_edge_usage = {(u, v): 0 for u, v in graph.edges()}\n        system_graph = graph\n        system_forecast = ground_truth_weather[current_time : current_time + timedelta(hours=8)]\n\n        # --- Event Tracking ---\n        events.sort(key=lambda e: e['time'])\n        next_event_idx = 0\n\n        # --- Main Simulation Loop ---\n        while len(completed_jobs) < len(jobs):\n            # 1. EVENT TRIGGER CHECK\n            if re_planning_enabled and next_event_idx < len(events) and current_time >= events[next_event_idx]['time']:\n                event = events[next_event_idx]\n                print(f\"\\nðŸ”” EVENT @ {current_time.strftime('%H:%M:%S')}: {event['description']} ðŸ””\")\n                next_event_idx += 1\n                if 'forecast_update' in event: \n                    system_forecast = event['forecast_update']\n                if 'graph_update' in event: \n                    system_graph = event['graph_update']\n\n                print(\"   â–¶ Pausing simulation for autonomous re-planning...\")\n                in_progress_jobs = {v['current_job']['id'] for v in vehicles if v.get('current_job')}\n                queued_jobs = [job for queue in job_queues.values() for job in queue]\n                jobs_to_replan = [job for job in queued_jobs if job['id'] not in in_progress_jobs]\n\n                if jobs_to_replan:\n                    for v in vehicles: \n                        v['available_time'] = current_time\n                    _, new_plan_ids = optimizer_func(jobs_to_replan, vehicles, system_forecast, gnn_model, system_graph, weather_aware)\n                    for q in job_queues.values(): \n                        q.clear()\n                    for i, job_id in enumerate(new_plan_ids):\n                        vehicle_id = vehicles[i % len(vehicles)]['id']\n                        job_queues[vehicle_id].append(job_map[job_id])\n                    print(f\"   âœ… New plan with {len(new_plan_ids)} jobs adopted. Resuming simulation.\")\n                else:\n                    print(\"   ...No queued jobs to replan. Resuming simulation.\")\n                print(\"-\" * 30)\n\n            # 2. VEHICLE STATE MACHINE LOGIC\n            for v in vehicles:\n                if v['status'] == 'moving_on_edge' and current_time >= v['edge_finish_time']:\n                    if len(v['path']) > 1:\n                        prev_edge = (v['path'][0], v['path'][1])\n                        active_edge_usage[prev_edge] = max(0, active_edge_usage[prev_edge] - 1)\n                        v['location'] = v['path'][1]\n                        v['path'] = v['path'][1:]\n                        v['status'] = 'en_route'\n                        v['edge_finish_time'] = None\n\n            for v in vehicles:\n                if v['status'] in ['idle', 'en_route'] and len(v.get('path', [])) <= 1:\n                    v['path'] = []\n                    if v.get('current_job') and v['location'] == v['current_job']['destination']:\n                        completed_jobs.add(v['current_job']['id'])\n                        v['current_job'] = None\n                    if not v.get('current_job') and job_queues[v['id']]:\n                        v['current_job'] = job_queues[v['id']].pop(0)\n                        v['path'] = self.safe_path_calculation(system_graph, v['location'], v['current_job']['source'])\n                        if v['path'] is None:\n                            v['status'] = 'blocked'\n                            continue\n                        v['status'] = 'en_route'\n                    elif v.get('current_job') and v['location'] == v['current_job']['source']:\n                        v['path'] = self.safe_path_calculation(system_graph, v['location'], v['current_job']['destination'])\n                        if v['path'] is None:\n                            v['status'] = 'blocked'\n                            continue\n                        v['status'] = 'en_route'\n                    else:\n                        v['status'] = 'idle'\n\n            for v in vehicles:\n                if v['status'] == 'en_route' and len(v['path']) > 1:\n                    u, next_node = v['path'][0], v['path'][1]\n                    edge = (u, next_node)\n                    if not graph.has_edge(u, next_node):\n                        v['status'] = 'blocked'\n                        continue\n\n                    edge_data = {**graph.edges[edge], 'start_node': u, 'end_node': next_node}\n                    weather_now = SyntheticDataGenerator.get_weather_at_time(current_time, ground_truth_weather)\n                    soil = 0\n                    if not edge_data['paved'] and weather_now['rain_intensity'] > 1: \n                        soil = 2\n\n                    # Use physics engine for travel time calculation\n                    data_generator = SyntheticDataGenerator(graph, ground_truth_weather, {})\n                    mean_time, _, _ = data_generator.calculate_ground_truth_travel(\n                        edge_data, active_edge_usage[edge], weather_now, v['type'], current_time, soil)\n                    \n                    v['status'] = 'moving_on_edge'\n                    v['edge_finish_time'] = current_time + timedelta(seconds=mean_time)\n                    active_edge_usage[edge] += 1\n\n            # 3. ADVANCE SIMULATION CLOCK\n            current_time += time_step\n            if current_time > initial_states[0]['available_time'] + timedelta(hours=24):\n                print(f\"ðŸ›‘ SIMULATION TIMEOUT after 24 hours. {len(completed_jobs)}/{len(jobs)} jobs completed.\")\n                break\n\n        # Calculate final makespan\n        finish_times = [v['edge_finish_time'] for v in vehicles if v.get('edge_finish_time')]\n        if finish_times:\n            last_finish_time = max(finish_times + [current_time])\n        else:\n            last_finish_time = current_time\n            \n        makespan = (last_finish_time - initial_states[0]['available_time']).total_seconds() / 3600.0\n        print(f\"ðŸ Simulation Finished. Makespan: {makespan:.2f} Hours\")\n        return makespan\n\n# Initialize simulation manager\nsimulation_manager = AdaptiveSimulation(site_graph, weather_df)","metadata":{"_uuid":"1d9b48b2-6eb2-4c4c-891e-e8f6548b46a6","_cell_guid":"1865c389-953e-4bef-aea6-30287bec0ba9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-30T09:32:37.184019Z","iopub.execute_input":"2025-09-30T09:32:37.184185Z","iopub.status.idle":"2025-09-30T09:32:37.206272Z","shell.execute_reply.started":"2025-09-30T09:32:37.184171Z","shell.execute_reply":"2025-09-30T09:32:37.205513Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport matplotlib.pyplot as plt\nimport copy\nimport numpy as np\n\nclass ExperimentRunner:\n    \"\"\"Runs comprehensive experiments comparing different optimization approaches\"\"\"\n    \n    def __init__(self, site_graph, weather_df, simulation_manager):\n        self.site_graph = site_graph\n        self.weather_df = weather_df\n        self.simulation_manager = simulation_manager\n        \n        # Define vehicle fleet\n        self.INITIAL_VEHICLE_STATES = [\n            {'id': 0, 'type': 'truck', 'location': 'Main_Gate', 'available_time': SyntheticDataGenerator.SIMULATION_START_TIME},\n            {'id': 1, 'type': 'truck', 'location': 'Contractor_Gate', 'available_time': SyntheticDataGenerator.SIMULATION_START_TIME},\n            {'id': 2, 'type': 'forklift', 'location': 'Laydown_A', 'available_time': SyntheticDataGenerator.SIMULATION_START_TIME},\n        ]\n        \n        # Define complex job scenarios\n        self.COMPLEX_JOBS = [\n            {'task': 'Deliver Rebar', 'sequence': [('Laydown_A', 'Building_1_N')]},\n            {'task': 'Clear Debris from Pit', 'sequence': [('Foundation_Pit', 'Waste_Disposal')]},\n            {'task': 'Move Scaffolding', 'sequence': [('Laydown_B', 'Building_2_W')]},\n            {'task': 'Prefab Wall Delivery', 'sequence': [('Fabrication_Yard', 'Building_1_S')]},\n            {'task': 'Multi-stop Debris Clearance', 'sequence': [('Building_1_S', 'Waste_Disposal'), ('Building_2_E', 'Waste_Disposal')]},\n            {'task': 'Small Tool Delivery', 'sequence': [('Laydown_A', 'Foundation_Pit')]},\n            {'task': 'Deliver piping', 'sequence': [('Laydown_A', 'Building_2_W')]},\n            {'task': 'Move excess soil', 'sequence': [('Foundation_Pit', 'Waste_Disposal')]},\n            {'task': 'Transport fabricated component', 'sequence': [('Fabrication_Yard', 'Building_2_E')]}\n        ]\n        \n        self.JOBS_FOR_PLANNING = self._flatten_jobs()\n        \n    def _flatten_jobs(self):\n        \"\"\"Flatten complex multi-stop jobs into single-leg tasks\"\"\"\n        jobs_for_planning = []\n        job_counter = 0\n        for job in self.COMPLEX_JOBS:\n            for u, v in job['sequence']:\n                jobs_for_planning.append({'id': job_counter, 'source': u, 'destination': v})\n                job_counter += 1\n        return jobs_for_planning\n    \n    def setup_disruption_scenario(self):\n        \"\"\"Set up realistic disruption scenario with weather and path closures\"\"\"\n        INITIAL_FORECAST = self.weather_df[SyntheticDataGenerator.SIMULATION_START_TIME : \n                                         SyntheticDataGenerator.SIMULATION_START_TIME + timedelta(hours=8)]\n\n        # The actual weather includes a surprise storm\n        ground_truth_weather = self.weather_df.copy()\n        storm_start = SyntheticDataGenerator.SIMULATION_START_TIME + timedelta(hours=2)\n        storm_end = SyntheticDataGenerator.SIMULATION_START_TIME + timedelta(hours=4)\n        ground_truth_weather.loc[storm_start:storm_end, 'rain'] = 8.0\n        ground_truth_weather.loc[storm_start:storm_end, 'rain_intensity'] = 3\n        print(f\"Disruption 1: A surprise storm will occur between {storm_start.strftime('%H:%M')} and {storm_end.strftime('%H:%M')}.\")\n\n        # The new forecast, revealing the storm, becomes available at T+45min\n        updated_forecast = ground_truth_weather[SyntheticDataGenerator.SIMULATION_START_TIME : \n                                              SyntheticDataGenerator.SIMULATION_START_TIME + timedelta(hours=8)]\n\n        # A critical path on the main circulation loop is blocked by a crane at T+3h\n        broken_down_graph = self.site_graph.copy()\n        blocked_edge = ('Building_1_S', 'Main_Gate')\n        if broken_down_graph.has_edge(*blocked_edge):\n            broken_down_graph.remove_edge(*blocked_edge)\n            print(f\"Disruption 2: Path '{blocked_edge[0]}'->'{blocked_edge[1]}' will be blocked at { (SyntheticDataGenerator.SIMULATION_START_TIME + timedelta(hours=3)).strftime('%H:%M') }.\")\n\n        # Package disruptions into events\n        simulation_events = [\n            {\n                'time': SyntheticDataGenerator.SIMULATION_START_TIME + timedelta(minutes=45),\n                'description': \"Weather Forecast Update: Major Storm Predicted!\",\n                'forecast_update': updated_forecast\n            },\n            {\n                'time': SyntheticDataGenerator.SIMULATION_START_TIME + timedelta(hours=3),\n                'description': \"Site Disruption: Main Gate Access Route Blocked!\",\n                'graph_update': broken_down_graph\n            }\n        ]\n        \n        return INITIAL_FORECAST, ground_truth_weather, updated_forecast, broken_down_graph, simulation_events\n    \n    def run_all_experiments(self, single_obj_optimizer, multi_obj_optimizer, static_optimizer):\n        \"\"\"Run comprehensive comparison of all optimization approaches\"\"\"\n        print(f\"âœ… Complex scenario defined with {len(self.INITIAL_VEHICLE_STATES)} vehicles and {len(self.JOBS_FOR_PLANNING)} total tasks.\")\n        \n        # Setup disruption scenario\n        INITIAL_FORECAST, ground_truth_weather, updated_forecast, broken_down_graph, simulation_events = self.setup_disruption_scenario()\n        \n        results = {}\n        \n        # --- Model 1: Static Baseline ---\n        static_plan, static_plan_ids = static_optimizer.run_static_optimizer(\n            self.JOBS_FOR_PLANNING, self.INITIAL_VEHICLE_STATES, self.site_graph)\n        results['Static Baseline'] = self.simulation_manager.run_adaptive_simulation(\n            static_plan_ids, self.JOBS_FOR_PLANNING, self.INITIAL_VEHICLE_STATES, self.site_graph, \n            ground_truth_weather, optimizer_func=None, gnn_model=None, weather_aware=False, \n            events=simulation_events)\n\n        # --- Model 2: Weather-Agnostic GNN (Static Plan) ---\n        agnostic_plan, agnostic_plan_ids = single_obj_optimizer_agnostic.run_ga_optimizer(\n            self.JOBS_FOR_PLANNING, self.INITIAL_VEHICLE_STATES, INITIAL_FORECAST)\n        \n        # --- Model 3: Weather-Aware GNN (Static Plan) ---\n        aware_plan_static, aware_plan_static_ids = single_obj_optimizer_aware.run_ga_optimizer(\n            self.JOBS_FOR_PLANNING, self.INITIAL_VEHICLE_STATES, INITIAL_FORECAST)\n        \n        # --- Model 4: Single-Objective Adaptive Digital Twin ---\n        results['GA-GNN (Aware, Adaptive)'] = self.simulation_manager.run_adaptive_simulation(\n            aware_plan_static_ids, self.JOBS_FOR_PLANNING, self.INITIAL_VEHICLE_STATES, self.site_graph, \n            ground_truth_weather, optimizer_func=single_obj_optimizer_aware.run_ga_optimizer, \n            gnn_model=gnn_model_aware, weather_aware=True, events=simulation_events)\n\n        # --- Model 5: Multi-Objective Adaptive Digital Twin ---\n        print(\"\\n--- Generating Initial Plan from Pareto Front ---\")\n        pareto_front = multi_obj_optimizer.run_nsga2_optimizer(\n            self.JOBS_FOR_PLANNING, self.INITIAL_VEHICLE_STATES, INITIAL_FORECAST, \n            gnn_model_aware, self.site_graph)\n\n        if pareto_front:\n            solutions = np.array([list(ind.fitness.values) for ind in pareto_front])\n            fastest_idx = np.argmin(solutions[:, 0])\n            fastest_plan_ids = list(pareto_front[fastest_idx])\n            print(f\"Selected 'Fastest' plan from Pareto front as the initial plan.\")\n\n            def replan_with_nsga2_fastest(jobs, states, weather, gnn, graph, weather_aware):\n                \"\"\"Wrapper for NSGA-II re-planning that selects fastest solution\"\"\"\n                hof = multi_obj_optimizer.run_nsga2_optimizer(jobs, states, weather, gnn, graph)\n                if not hof: \n                    return [], []\n                new_solutions = np.array([list(ind.fitness.values) for ind in hof])\n                new_fastest_idx = np.argmin(new_solutions[:, 0])\n                best_plan_ids = list(hof[new_fastest_idx])\n                dummy_plan = [[] for _ in states]\n                for i, job_id in enumerate(best_plan_ids):\n                    dummy_plan[i % len(states)].append(job_id)\n                return dummy_plan, best_plan_ids\n\n            results['Multi-Obj (Fastest, Adaptive)'] = self.simulation_manager.run_adaptive_simulation(\n                fastest_plan_ids, self.JOBS_FOR_PLANNING, self.INITIAL_VEHICLE_STATES, self.site_graph, \n                ground_truth_weather, optimizer_func=replan_with_nsga2_fastest, \n                gnn_model=gnn_model_aware, weather_aware=True, events=simulation_events)\n        else:\n            print(\"WARNING: Pareto front is empty. Skipping Multi-Objective Champion model.\")\n\n        return results\n    \n    def visualize_results(self, results):\n        \"\"\"Visualize experiment results with comprehensive analysis\"\"\"\n        sorted_results = sorted(results.items(), key=lambda item: item[1])\n        print(\"\\n\\n\" + \"=\"*60)\n        print(\"--- ðŸ“Š FINAL PERFORMANCE COMPARISON ðŸ“Š ---\")\n        print(\"=\"*60)\n        for name, makespan in sorted_results:\n            print(f\"{name:<35}: {makespan:.2f} Hours\")\n        print(\"=\"*60)\n\n        labels = [name for name, score in sorted_results]\n        scores = [score for name, score in sorted_results]\n        colors = ['grey', 'lightcoral', 'skyblue', 'darkorange', 'forestgreen']\n        \n        plt.figure(figsize=(14, 8))\n        bars = plt.barh(labels, scores, color=colors[:len(labels)])\n        plt.xlabel(\"Total Project Makespan (Hours)\")\n        plt.ylabel(\"Planning & Control Model\")\n        plt.title(\"Figure: Final Model Performance in Disrupted Scenario\", fontsize=16)\n        plt.gca().invert_yaxis()\n        plt.tight_layout()\n\n        for i, bar in enumerate(bars):\n            width = bar.get_width()\n            plt.text(width + 0.05, bar.get_y() + bar.get_height()/2, f'{width:.2f} hrs', \n                    ha='left', va='center', fontsize=11, weight='bold')\n\n        # Calculate improvement metrics\n        try:\n            baseline_score = results['GA-GNN (Aware, Static)']\n            if 'Multi-Obj (Fastest, Adaptive)' in results:\n                champion_score = results['Multi-Obj (Fastest, Adaptive)']\n                improvement = ((baseline_score - champion_score) / baseline_score) * 100\n                print(f\"\\nðŸ† The adaptive multi-objective model showed a {improvement:.2f}% improvement over the best static plan.\")\n        except (KeyError, ZeroDivisionError):\n            print(\"\\nCould not calculate final improvement metric.\")\n\n        plt.xlim(right=max(scores) * 1.20)\n        plt.show()\n\n# Run comprehensive experiments\nexperiment_runner = ExperimentRunner(site_graph, weather_df, simulation_manager)\nresults = experiment_runner.run_all_experiments(single_obj_optimizer_aware, multi_obj_optimizer, static_optimizer)\nexperiment_runner.visualize_results(results)","metadata":{"_uuid":"329a4c42-e6e2-437f-823e-a31eadf10149","_cell_guid":"a9e662a4-f4b1-45a0-b417-293dc1e7e8b0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-30T09:32:37.207302Z","iopub.execute_input":"2025-09-30T09:32:37.207588Z","iopub.status.idle":"2025-09-30T09:33:45.041461Z","shell.execute_reply.started":"2025-09-30T09:32:37.207566Z","shell.execute_reply":"2025-09-30T09:33:45.040642Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass ParetoAnalyzer:\n    \"\"\"Analyzes and visualizes Pareto front solutions\"\"\"\n    \n    def __init__(self, multi_obj_optimizer, jobs, states, weather_forecast):\n        self.multi_obj_optimizer = multi_obj_optimizer\n        self.jobs = jobs\n        self.states = states\n        self.weather_forecast = weather_forecast\n        \n    def analyze_pareto_front(self):\n        \"\"\"Run NSGA-II and analyze the resulting Pareto front\"\"\"\n        print(\"--- Generating and Analyzing Pareto Front ---\")\n        pareto_front = self.multi_obj_optimizer.run_nsga2_optimizer(\n            self.jobs, self.states, self.weather_forecast, gnn_model_aware, site_graph)\n\n        if not pareto_front:\n            print(\"Execution Warning: No solutions were found by the NSGA-II optimizer.\")\n            return None\n\n        # Extract the fitness values (Time, Cost, Risk) from each non-dominated solution\n        solutions = np.array([list(ind.fitness.values) for ind in pareto_front])\n\n        # Separate the objectives into individual arrays for analysis and plotting\n        times = solutions[:, 0]  # Makespan in Hours\n        costs = solutions[:, 1]  # Total Fuel in Liters\n        risks = solutions[:, 2]  # Sum of Variances (Risk Score)\n\n        # Identify three key representative solutions from the front\n        fastest_idx = np.argmin(times)\n        cheapest_idx = np.argmin(costs)\n        safest_idx = np.argmin(risks)\n\n        best_time_solution = solutions[fastest_idx]\n        best_cost_solution = solutions[cheapest_idx]\n        best_risk_solution = solutions[safest_idx]\n\n        print(\"\\n\" + \"=\"*50)\n        print(\"--- Analysis of Representative Optimal Solutions ---\")\n        print(\"=\"*50)\n        print(f\"Fastest Plan (Greedy):\")\n        print(f\"  Makespan: {best_time_solution[0]:.2f} hrs | Fuel Cost: {best_time_solution[1]:.2f} L | Risk Score: {best_time_solution[2]:.2f}\")\n        print(\"\\n\")\n        print(f\"Cheapest Plan (Economical):\")\n        print(f\"  Makespan: {best_cost_solution[0]:.2f} hrs | Fuel Cost: {best_cost_solution[1]:.2f} L | Risk Score: {best_cost_solution[2]:.2f}\")\n        print(\"\\n\")\n        print(f\"Safest Plan (Reliable/Low-Risk):\")\n        print(f\"  Makespan: {best_risk_solution[0]:.2f} hrs | Fuel Cost: {best_risk_solution[1]:.2f} L | Risk Score: {best_risk_solution[2]:.2f}\")\n        print(\"=\"*50)\n\n        return pareto_front, solutions, (best_time_solution, best_cost_solution, best_risk_solution)\n    \n    def visualize_pareto_3d(self, solutions, representative_solutions):\n        \"\"\"Create 3D visualization of Pareto front\"\"\"\n        times, costs, risks = solutions[:, 0], solutions[:, 1], solutions[:, 2]\n        best_time, best_cost, best_risk = representative_solutions\n\n        fig = plt.figure(figsize=(14, 12))\n        ax = fig.add_subplot(111, projection='3d')\n\n        # Create the 3D scatter plot of all solutions on the Pareto front\n        scatter = ax.scatter(times, costs, risks, c=times, cmap='viridis', s=60, alpha=0.8, edgecolors='k', linewidth=0.5)\n\n        # Highlight the representative solutions with larger markers and labels\n        ax.scatter(best_time[0], best_time[1], best_time[2], c='red', s=200, marker='*', label='Fastest')\n        ax.text(best_time[0]*1.01, best_time[1]*1.01, best_time[2]*1.01, \"Fastest\", color='red', fontsize=12)\n\n        ax.scatter(best_cost[0], best_cost[1], best_cost[2], c='blue', s=200, marker='P', label='Cheapest')\n        ax.text(best_cost[0]*1.01, best_cost[1]*1.01, best_cost[2]*1.01, \"Cheapest\", color='blue', fontsize=12)\n\n        ax.scatter(best_risk[0], best_risk[1], best_risk[2], c='green', s=200, marker='D', label='Safest')\n        ax.text(best_risk[0]*1.01, best_risk[1]*1.01, best_risk[2]*1.01, \"Safest\", color='green', fontsize=12)\n\n        # Set titles and labels for clarity\n        ax.set_title('Pareto Front: Optimal Trade-offs (Time vs. Cost vs. Risk)', fontsize=18, pad=20)\n        ax.set_xlabel('\\nMakespan (Hours) - Lower is Better', fontsize=12)\n        ax.set_ylabel('\\nTotal Fuel (Liters) - Lower is Better', fontsize=12)\n        ax.set_zlabel('\\nLateness Risk Score - Lower is Better', fontsize=12)\n\n        # Invert axes so that the \"best\" point (0,0,0) is visually in the corner\n        ax.invert_xaxis()\n        ax.invert_yaxis()\n        ax.invert_zaxis()\n\n        # Add a color bar to explain the color mapping\n        cbar = fig.colorbar(scatter, shrink=0.6, aspect=20, pad=0.01)\n        cbar.set_label('Makespan (Hours)', fontsize=12)\n\n        ax.legend(fontsize=12)\n        plt.show()\n        \n    def generate_green_vs_lean_table(self, representative_solutions):\n        \"\"\"Generate quantitative analysis of sustainability trade-offs\"\"\"\n        best_time, best_cost, _ = representative_solutions\n        \n        # Define the CO2 conversion factor (kg of CO2 per liter of diesel)\n        CO2_FACTOR = 2.68\n\n        # Calculate metrics for the table\n        lean_makespan = best_time[0]\n        lean_fuel = best_time[1]\n        lean_co2 = lean_fuel * CO2_FACTOR\n\n        green_makespan = best_cost[0]\n        green_fuel = best_cost[1]\n        green_co2 = green_fuel * CO2_FACTOR\n\n        # Calculate the percentage trade-offs\n        makespan_increase_pct = ((green_makespan - lean_makespan) / lean_makespan) * 100\n        co2_reduction_pct = ((lean_co2 - green_co2) / lean_co2) * 100\n\n        # Create a Pandas DataFrame for clean formatting\n        tradeoff_data = {\n            'Metric': ['Project Makespan (Hours)', 'Total Fuel Consumed (Liters)', 'Total COâ‚‚ Emissions (kg)'],\n            'Lean Plan (Fastest)': [f\"{lean_makespan:.2f}\", f\"{lean_fuel:.2f}\", f\"{lean_co2:.2f}\"],\n            'Green Plan (Most Fuel-Efficient)': [f\"{green_makespan:.2f}\", f\"{green_fuel:.2f}\", f\"{green_co2:.2f}\"],\n            'Trade-Off': [f\"+{makespan_increase_pct:.1f}% Time\", \"-\", f\"-{co2_reduction_pct:.1f}% Emissions\"]\n        }\n        tradeoff_df = pd.DataFrame(tradeoff_data)\n\n        print(\"\\n\\n\" + \"=\"*70)\n        print(\"--- ðŸŒ Table: The Green vs. Lean Trade-Off in Construction Logistics ðŸŒ ---\")\n        print(\"=\"*70)\n        print(tradeoff_df.to_markdown(index=False))\n        print(\"=\"*70)\n        print(f\"\\nKey Finding: Opting for the 'Green' plan reduces COâ‚‚ emissions by {co2_reduction_pct:.1f}% at the cost of a {makespan_increase_pct:.1f}% increase in project makespan.\")\n\n# Run Pareto analysis\nINITIAL_FORECAST = weather_df[SyntheticDataGenerator.SIMULATION_START_TIME : \n                             SyntheticDataGenerator.SIMULATION_START_TIME + timedelta(hours=8)]\n\n# Create experiment runner to get jobs and states\nexperiment_runner = ExperimentRunner(site_graph, weather_df, simulation_manager)\n\npareto_analyzer = ParetoAnalyzer(multi_obj_optimizer, experiment_runner.JOBS_FOR_PLANNING, \n                               experiment_runner.INITIAL_VEHICLE_STATES, INITIAL_FORECAST)\n\npareto_results = pareto_analyzer.analyze_pareto_front()\nif pareto_results:\n    pareto_front, solutions, representative_solutions = pareto_results\n    pareto_analyzer.visualize_pareto_3d(solutions, representative_solutions)\n    pareto_analyzer.generate_green_vs_lean_table(representative_solutions)","metadata":{"_uuid":"309b47cf-926c-4a9b-bde5-43d792c429ee","_cell_guid":"eaa205f8-c0a9-4b8d-be2b-0e681368a8de","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-09-30T09:33:45.042564Z","iopub.execute_input":"2025-09-30T09:33:45.042871Z","iopub.status.idle":"2025-09-30T09:33:54.271213Z","shell.execute_reply.started":"2025-09-30T09:33:45.042843Z","shell.execute_reply":"2025-09-30T09:33:54.270435Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}