{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n# Install required libraries\n# PyTorch Geometric (PyG) requires specific torch versions.\n# We first install torch, then the PyG packages.\n!pip install torch torchvision torau dio --index-url https://download.pytorch.org/whl/cu118 -q\n!pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu118.html -q\n!pip install torch_geometric -q\n!pip install openmeteo-requests requests-cache retry-requests numpy pandas networkx scikit-learn deap matplotlib -q\n\n# Import libraries\nimport openmeteo_requests\nimport requests_cache\nimport pandas as pd\nfrom retry_requests import retry\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport random\nimport time\nfrom datetime import datetime, timedelta\nimport math\nfrom math import sqrt\nimport copy\n\n# PyTorch and PyG imports\nimport torch\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import SAGEConv, GATConv\nimport torch.nn.functional as F\n\n# GA and other utility imports\nfrom deap import base, creator, tools, algorithms\n\nprint(\"‚úÖ Setup Complete. All libraries installed and imported.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-29T20:22:49.193486Z","iopub.execute_input":"2025-09-29T20:22:49.193725Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement torau (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for torau\u001b[0m\u001b[31m\n\u001b[0m‚úÖ Setup Complete. All libraries installed and imported.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import networkx as nx\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nimport numpy as np\nimport random\n\ndef create_large_scale_site_graph():\n    \"\"\"\n    Creates a more complex and realistic construction site graph, representing a larger project\n    with specialized zones and structured traffic flow.\n    \"\"\"\n    G = nx.DiGraph()\n\n    # Define a larger set of nodes with specialized roles and positions for visualization\n    node_positions = {\n        # Entry, Exit & Main Logistics Hubs\n        'Main_Gate': (0, 50),\n        'Contractor_Gate': (0, 150),\n        'Laydown_A': (20, 120),       # Steel & Rebar Storage\n        'Laydown_B': (20, 30),        # General Materials Storage\n        'Fabrication_Yard': (180, 130), # Prefabrication Area\n        'Fuel_Depot': (100, 0),         # Refueling Station\n        'Waste_Disposal': (180, 20),    # Waste & Debris Collection\n\n        # Work Zones (Representing multiple buildings or major areas)\n        'Building_1_N': (80, 180),      # North side of Building 1\n        'Building_1_S': (80, 140),      # South side of Building 1\n        'Building_2_W': (150, 100),     # West side of Building 2\n        'Building_2_E': (180, 100),     # East side of Building 2\n        'Foundation_Pit': (120, 60),    # Major excavation area\n    }\n    for node, pos in node_positions.items():\n        G.add_node(node, pos=pos)\n\n    # Define a more extensive edge network, including one-way roads to manage traffic flow\n    edge_definitions = [\n        # Main access loop (designed as a one-way circulation road)\n        ('Main_Gate', 'Laydown_B', {'paved': True, 'one_way': True}),\n        ('Laydown_B', 'Fuel_Depot', {'paved': True, 'one_way': True}),\n        ('Fuel_Depot', 'Waste_Disposal', {'paved': True, 'one_way': True}),\n        ('Waste_Disposal', 'Building_2_E', {'paved': True, 'one_way': True}),\n        ('Building_2_E', 'Fabrication_Yard', {'paved': True, 'one_way': True}),\n        ('Fabrication_Yard', 'Building_1_N', {'paved': True, 'one_way': True}),\n        ('Building_1_N', 'Contractor_Gate', {'paved': True, 'one_way': True}),\n        ('Contractor_Gate', 'Laydown_A', {'paved': True, 'one_way': True}),\n        ('Laydown_A', 'Building_1_S', {'paved': True, 'one_way': True}),\n        ('Building_1_S', 'Main_Gate', {'paved': True, 'one_way': True}),\n\n        # Two-way connector paths and access roads to work zones\n        ('Laydown_A', 'Laydown_B', {'paved': True}),\n        ('Building_1_S', 'Foundation_Pit', {'paved': False}), # Unpaved access to pit\n        ('Foundation_Pit', 'Building_2_W', {'paved': False}), # Unpaved access to pit\n        ('Building_2_W', 'Building_2_E', {'paved': True}),\n        ('Building_1_S', 'Laydown_A', {'paved': True}), # Short-cut\n        ('Fuel_Depot', 'Foundation_Pit', {'paved': False}), # Direct unpaved access\n    ]\n\n    for u, v, attrs in edge_definitions:\n        # Calculate length from positions and add some noise for realism\n        pos_u, pos_v = np.array(node_positions[u]), np.array(node_positions[v])\n        # Use Euclidean distance scaled up to represent meters on a large site\n        length = np.linalg.norm(pos_u - pos_v) * 1.5\n        attrs['length'] = int(length)\n        attrs['slope'] = random.randint(-4, 4) # Assign a random slope\n        attrs['base_speed_limit'] = 10 if attrs.get('paved', False) else 5\n        attrs['base_travel_time'] = attrs['length'] / attrs['base_speed_limit']\n\n        G.add_edge(u, v, **attrs)\n        # If not explicitly a one-way road, add the reverse edge\n        if not attrs.get('one_way', False):\n            # Create a new attribute dict for the reverse edge to allow different slopes\n            rev_attrs = attrs.copy()\n            rev_attrs['slope'] = -attrs['slope']\n            G.add_edge(v, u, **rev_attrs)\n\n    return G\n\n# --- Initialization and Schedule Definition ---\n# Create the graph instance\nsite_graph = create_large_scale_site_graph()\n\n# Define 4D scheduled closures, updated for the new node names\nSCHEDULED_CLOSURES = {\n    ('Foundation_Pit', 'Building_2_W'): (datetime.fromisoformat(\"2023-07-01T13:00:00\"), datetime.fromisoformat(\"2023-07-01T15:00:00\")),\n    ('Building_2_W', 'Foundation_Pit'): (datetime.fromisoformat(\"2023-07-01T13:00:00\"), datetime.fromisoformat(\"2023-07-01T15:00:00\"))\n}\n\nprint(f\"‚úÖ Large-scale site graph created with {site_graph.number_of_nodes()} nodes and {site_graph.number_of_edges()} edges.\")\n\n# --- Visualization of the Complex Graph ---\npos = nx.get_node_attributes(site_graph, 'pos')\npaved_edges = [edge for edge, attrs in site_graph.edges.items() if attrs.get('paved', False)]\nunpaved_edges = [edge for edge, attrs in site_graph.edges.items() if not attrs.get('paved', False)]\n\nplt.figure(figsize=(20, 14))\n# Draw nodes and labels\nnx.draw_networkx_nodes(site_graph, pos, node_size=3500, node_color='skyblue')\nnx.draw_networkx_labels(site_graph, pos, font_size=10, font_weight='bold')\n\n# Draw edges with different styles\nnx.draw_networkx_edges(site_graph, pos, edgelist=paved_edges,\n                       width=2.0, alpha=0.7, edge_color='black',\n                       connectionstyle='arc3,rad=0.1', arrowsize=20)\nnx.draw_networkx_edges(site_graph, pos, edgelist=unpaved_edges,\n                       width=1.5, alpha=0.8, edge_color='brown', style='dashed',\n                       connectionstyle='arc3,rad=0.1', arrowsize=20)\n\nplt.title(\"Large-Scale Construction Site Layout\", fontsize=22)\nplt.xlabel(\"X Coordinate (m)\")\nplt.ylabel(\"Y Coordinate (m)\")\nplt.grid(True)\nplt.legend(handles=[plt.Line2D([0], [0], color='black', lw=2, label='Paved Road'),\n                     plt.Line2D([0], [0], color='brown', lw=2, ls='--', label='Unpaved Path')],\n           fontsize=14)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import openmeteo_requests\nimport requests_cache\nimport pandas as pd\nfrom retry_requests import retry\nimport matplotlib.pyplot as plt\n\ndef get_weather_data(latitude, longitude, start_date, end_date):\n    \"\"\"\n    Fetches historical hourly weather data from the Open-Meteo API.\n    It uses caching to avoid re-downloading data during development.\n    \"\"\"\n    # Setup the Open-Meteo API client with cache and retry logic\n    cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n    retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n    openmeteo = openmeteo_requests.Client(session=retry_session)\n\n    # Define the API request parameters\n    url = \"https://archive-api.open-meteo.com/v1/archive\"\n    params = {\n        \"latitude\": latitude,\n        \"longitude\": longitude,\n        \"start_date\": start_date,\n        \"end_date\": end_date,\n        \"hourly\": [\"temperature_2m\", \"rain\", \"wind_speed_10m\"]\n    }\n\n    # Make the API call\n    responses = openmeteo.weather_api(url, params=params)\n    response = responses[0]\n\n    # Process the response into a Pandas DataFrame\n    hourly = response.Hourly()\n    hourly_data = {\n        \"temperature_2m\": hourly.Variables(0).ValuesAsNumpy(),\n        \"rain\": hourly.Variables(1).ValuesAsNumpy(),\n        \"wind_speed_10m\": hourly.Variables(2).ValuesAsNumpy(),\n    }\n    df = pd.DataFrame(data=hourly_data)\n\n    # Create a robust DatetimeIndex from the API's metadata\n    start = pd.to_datetime(hourly.Time(), unit=\"s\")\n    end = pd.to_datetime(hourly.TimeEnd(), unit=\"s\")\n    interval = pd.Timedelta(seconds=hourly.Interval())\n    df.index = pd.date_range(start=start, end=end, freq=interval, inclusive=\"left\")\n\n    return df\n\ndef feature_engineer_weather(df):\n    \"\"\"\n    Adds engineered, construction-relevant features to the raw weather dataframe.\n    These categorical features are easier for a machine learning model to interpret.\n    \"\"\"\n    # Create rain intensity buckets (0: None, 1: Light, 2: Moderate, 3: Heavy)\n    # Thresholds are based on standard meteorological definitions (mm/hr)\n    df['rain_intensity'] = pd.cut(df['rain'],\n                                  bins=[-1, 0.1, 2.5, 7.6, 100],\n                                  labels=[0, 1, 2, 3],\n                                  right=True).astype(int)\n\n    # Create wind hazard flag (0: Safe, 1: Hazardous)\n    # Threshold based on levels where light equipment operation becomes risky (~55 km/h)\n    df['wind_hazard'] = (df['wind_speed_10m'] > 15).astype(int)\n\n    # Create heat stress buckets (0: Normal, 1: High, 2: Very High)\n    # Thresholds based on general guidance for outdoor work safety\n    df['heat_stress'] = pd.cut(df['temperature_2m'],\n                               bins=[-100, 28, 32, 100],\n                               labels=[0, 1, 2],\n                               right=False).astype(int)\n    return df\n\n# --- Execution ---\n# Fetch and process weather data for a construction site in London for July 2023.\nweather_df = get_weather_data(latitude=51.5085, longitude=-0.1257,\n                              start_date=\"2023-07-01\", end_date=\"2023-07-31\")\nweather_df = feature_engineer_weather(weather_df)\n\nprint(\"‚úÖ Weather data fetched and engineered successfully.\")\nprint(\"\\n--- Sample of Weather DataFrame with Engineered Features ---\")\nprint(weather_df.head())\n\n# --- Visualization ---\n# Plot a sample of the data to verify the feature engineering\nprint(\"\\n--- Visualizing a 5-day sample of engineered weather features ---\")\nsample_data = weather_df.first('5D')\nfig, axes = plt.subplots(3, 1, figsize=(15, 10), sharex=True)\n\n# Plot 1: Rain and Rain Intensity\nax1_twin = axes[0].twinx()\nsample_data['rain'].plot(ax=axes[0], color='blue', label='Rain (mm/hr)', style='-')\nsample_data['rain_intensity'].plot(ax=ax1_twin, color='red', label='Rain Intensity (Category)', drawstyle='steps-post')\naxes[0].set_ylabel(\"Rain (mm/hr)\")\nax1_twin.set_ylabel(\"Rain Intensity Category\")\naxes[0].legend(loc='upper left')\nax1_twin.legend(loc='upper right')\naxes[0].set_title(\"Rain vs. Engineered Rain Intensity\")\n\n# Plot 2: Temperature and Heat Stress\nax2_twin = axes[1].twinx()\nsample_data['temperature_2m'].plot(ax=axes[1], color='orange', label='Temperature (¬∞C)')\nsample_data['heat_stress'].plot(ax=ax2_twin, color='darkred', label='Heat Stress (Category)', drawstyle='steps-post')\naxes[1].set_ylabel(\"Temperature (¬∞C)\")\nax2_twin.set_ylabel(\"Heat Stress Category\")\naxes[1].legend(loc='upper left')\nax2_twin.legend(loc='upper right')\naxes[1].set_title(\"Temperature vs. Engineered Heat Stress\")\n\n# Plot 3: Wind and Wind Hazard\nax3_twin = axes[2].twinx()\nsample_data['wind_speed_10m'].plot(ax=axes[2], color='green', label='Wind Speed (m/s)')\nsample_data['wind_hazard'].plot(ax=ax3_twin, color='purple', label='Wind Hazard (Flag)', drawstyle='steps-post')\naxes[2].set_ylabel(\"Wind Speed (m/s)\")\nax3_twin.set_ylabel(\"Wind Hazard Flag\")\naxes[2].legend(loc='upper left')\nax3_twin.legend(loc='upper right')\naxes[2].set_title(\"Wind Speed vs. Engineered Wind Hazard\")\n\nplt.xlabel(\"Date\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nfrom datetime import datetime, timedelta\n\n# --- Fleet & Simulation Configuration with Fuel ---\n# This dictionary now defines a key physical property: the base fuel consumption rate.\nVEHICLE_PROPERTIES = {\n    # Fuel rates in Liters per Second of operation under ideal conditions\n    'truck': {\n        'base_speed_multiplier': 1.0,\n        'weather_sensitivity': 1.0,\n        'base_fuel_rate': 0.002  # e.g., 7.2 Liters/hour idle\n    },\n    'forklift': {\n        'base_speed_multiplier': 0.6,\n        'weather_sensitivity': 1.5,\n        'base_fuel_rate': 0.001  # e.g., 3.6 Liters/hour idle\n    }\n}\nSIMULATION_START_TIME = datetime.fromisoformat(\"2023-07-01T07:00:00\")\nSIMULATION_DURATION_HOURS = 168 # 1 week of data\n\n# --- Helper Functions (Unchanged) ---\ndef get_weather_at_time(sim_time, weather_df):\n    \"\"\"Retrieves the weather features for a given simulation timestamp using nearest-neighbor lookup.\"\"\"\n    indexer = weather_df.index.get_indexer([sim_time], method='nearest')\n    return weather_df.iloc[indexer[0]]\n\n# --- THIS FUNCTION IS UPGRADED TO RETURN FUEL CONSUMPTION ---\ndef calculate_ground_truth_travel(edge_data, num_vehicles_on_edge, weather_features, vehicle_type, current_time, soil_condition):\n    \"\"\"\n    The 'physics engine' of our simulation.\n    It now models and returns three key outputs for any given traversal:\n    1. mean_time: The expected travel time.\n    2. variance: The uncertainty of that travel time.\n    3. fuel_consumed: The estimated fuel cost for the traversal.\n    \"\"\"\n    # 1. Check for Absolute Blockers (e.g., 4D schedule conflicts)\n    edge_key = (edge_data['start_node'], edge_data['end_node'])\n    if edge_key in SCHEDULED_CLOSURES:\n        start_block, end_block = SCHEDULED_CLOSURES[edge_key]\n        if start_block <= current_time <= end_block:\n            return float('inf'), 0.0, 0.0 # Path is blocked, no time or fuel spent\n\n    # 2. Calculate Travel Time and Variance\n    vehicle_props = VEHICLE_PROPERTIES[vehicle_type]\n    base_time = edge_data['base_travel_time'] / vehicle_props['base_speed_multiplier']\n    congestion_factor = 1.0 + 0.2 * (num_vehicles_on_edge ** 2)\n    weather_and_soil_factor = 1.0\n    variance_factor = 0.05\n\n    # Apply penalties from weather and soil, ensuring indices are integers\n    rain_idx = int(weather_features['rain_intensity'])\n    heat_idx = int(weather_features['heat_stress'])\n    soil_idx = int(soil_condition)\n\n    if rain_idx > 0:\n        weather_and_soil_factor += [0, 0.1, 0.4, 0.7][rain_idx] * vehicle_props['weather_sensitivity']\n        variance_factor += [0, 0.1, 0.3, 0.2][rain_idx]\n    if heat_idx > 0:\n        weather_and_soil_factor += [0, 0.05, 0.15][heat_idx]\n        variance_factor += [0, 0.05, 0.1][heat_idx]\n    if not edge_data['paved'] and soil_idx > 0:\n        weather_and_soil_factor *= [1.0, 1.5, 3.0][soil_idx]\n        variance_factor += [0, 0.2, 0.4][soil_idx]\n\n    mean_time = base_time * congestion_factor * weather_and_soil_factor\n    final_mean_time = max(mean_time, base_time)\n    variance = (base_time * variance_factor)**2\n\n    # 3. NEW: Calculate Fuel Consumption\n    fuel_efficiency_factor = 1.0\n    # Positive slope increases fuel consumption significantly\n    if edge_data['slope'] > 0:\n        fuel_efficiency_factor += edge_data['slope'] * 0.15 # 15% more fuel per degree of slope\n    # Muddy conditions are very inefficient and require more power\n    if not edge_data['paved'] and soil_idx > 0:\n        fuel_efficiency_factor *= [1.0, 1.8, 3.5][soil_idx] # Up to 3.5x fuel burn in heavy mud\n\n    fuel_consumed = vehicle_props['base_fuel_rate'] * final_mean_time * fuel_efficiency_factor\n\n    return final_mean_time, variance, fuel_consumed\n\n# --- Stochastic Data Generation (Updated to log the new fuel data) ---\nprint(\"üöÄ Starting FAST synthetic data generation (with Fuel Cost)...\")\nedge_traversal_log = []\nnum_samples = 150\n\nfor i in range(num_samples):\n    if (i + 1) % 3000 == 0:\n        print(f\"   ...generated {i+1}/{num_samples} samples...\")\n\n    # Stochastically create a random scenario\n    u, v, edge_attrs = random.choice(list(site_graph.edges(data=True)))\n    sim_time = SIMULATION_START_TIME + timedelta(hours=random.uniform(0, SIMULATION_DURATION_HOURS))\n    weather_now = get_weather_at_time(sim_time, weather_df)\n    vehicle_type = random.choice(['truck', 'forklift'])\n    num_on_edge = random.randint(0, 2)\n\n    # Determine a realistic soil condition for the scenario\n    soil = 0\n    if not edge_attrs['paved']:\n        recent_weather = weather_df[sim_time - timedelta(hours=3):sim_time]\n        if not recent_weather.empty:\n            max_recent_rain = recent_weather['rain_intensity'].max()\n            if max_recent_rain >= 2: soil = 2\n            elif max_recent_rain == 1: soil = 1\n\n    # Call the new, upgraded physics engine\n    edge_attrs_with_nodes = {**edge_attrs, 'start_node': u, 'end_node': v}\n    mean_time, variance, fuel = calculate_ground_truth_travel(\n        edge_attrs_with_nodes, num_on_edge, weather_now, vehicle_type, sim_time, soil\n    )\n\n    # Log the results if the path is not blocked\n    if mean_time != float('inf'):\n      log_entry = {\n          'edge_start_node': u, 'edge_end_node': v,\n          'mean_travel_time': mean_time,\n          'variance': variance,\n          'fuel_consumed': fuel, # <-- NEW DATA POINT\n          'time_of_day': sim_time.hour + sim_time.minute / 60.0,\n          'num_vehicles_on_edge': num_on_edge,\n          **weather_now.to_dict(),\n          'soil_condition': soil,\n          'vehicle_type_truck': 1 if vehicle_type == 'truck' else 0\n      }\n      edge_traversal_log.append(log_entry)\n\ndataset_df = pd.DataFrame(edge_traversal_log)\nprint(f\"\\n‚úÖ Synthetic data generation complete. Generated {len(dataset_df)} records.\")\nprint(\"\\n--- Sample of Generated Dataset with Fuel ---\")\n# Display columns that show the new fuel data alongside factors that influence it\nprint(dataset_df[['edge_start_node', 'mean_travel_time', 'fuel_consumed', 'soil_condition']].head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch_geometric.data import Data\nfrom torch_geometric.loader import DataLoader\nfrom torch_geometric.nn import GATConv\nimport torch.nn.functional as F\nimport pandas as pd\n\n### MODIFICATION ###\n# Import the PyTorch Geometric version of DataParallel\nfrom torch_geometric.nn import DataParallel\n### END MODIFICATION ###\n\n# --- GNN Model Architecture (Graph Attention Network) ---\n# The model definition itself does not need to change.\nclass EdgePredictorGAT(torch.nn.Module):\n    \"\"\"\n    A Graph Neural Network model using Graph Attention (GAT) layers to predict\n    the mean and variance of travel time for edges in the site graph.\n    \"\"\"\n    def __init__(self, node_channels, edge_channels, hidden_channels):\n        super().__init__()\n        self.gat1 = GATConv(node_channels, hidden_channels, heads=2, concat=True)\n        self.gat2 = GATConv(hidden_channels * 2, hidden_channels, heads=1, concat=False)\n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(2 * hidden_channels + edge_channels, hidden_channels),\n            torch.nn.ReLU(),\n            torch.nn.Linear(hidden_channels, 2)\n        )\n\n    def forward(self, x, edge_index, edge_attr, edge_label_index):\n        # This forward pass logic is perfectly compatible with DataParallel.\n        # The 'for' loop for extracting edge_features might be a minor bottleneck,\n        # but DataParallel will still provide a significant speedup on the GNN and MLP layers.\n        x = F.elu(self.gat1(x, edge_index))\n        x = self.gat2(x, edge_index)\n        start_node_emb = x[edge_label_index[0]]\n        end_node_emb = x[edge_label_index[1]]\n\n        edge_features_list = []\n        for i in range(edge_label_index.shape[1]):\n            u, v = edge_label_index[0, i].item(), edge_label_index[1, i].item()\n            edge_idx = (edge_index.T == torch.tensor([u, v], device=x.device)).all(dim=1).nonzero(as_tuple=True)[0]\n            edge_features_list.append(edge_attr[edge_idx])\n        edge_features = torch.cat(edge_features_list, dim=0)\n\n        combined = torch.cat([start_node_emb, end_node_emb, edge_features], dim=1)\n        output = self.mlp(combined)\n        mean, log_var = output[:, 0], output[:, 1]\n        var = torch.exp(log_var)\n        return mean, var\n\n# --- Versatile GNN Training Function (Modified for Multi-GPU) ---\ndef train_gnn_model(gnn_type='GAT', dataset_df=dataset_df, epochs=50, weather_aware=True):\n    \"\"\"\n    Trains a GNN model. This version automatically uses all available GPUs for training.\n    \"\"\"\n    print(f\"\\n--- Training GNN Model (Variant: {gnn_type}, Weather-Aware: {weather_aware}) ---\")\n\n    # 1. Prepare graph structure and static features (on CPU)\n    node_mapping = {name: i for i, name in enumerate(site_graph.nodes())}\n    static_edge_features = torch.tensor([[d['length'], d['slope'], d['paved']] for _,_,d in site_graph.edges(data=True)], dtype=torch.float)\n    edge_index = torch.tensor(list(zip(*[(node_mapping[u], node_mapping[v]) for u,v in site_graph.edges()])), dtype=torch.long)\n\n    # 2. Prepare the full dataset for PyTorch Geometric (on CPU)\n    pyg_data_list = []\n    # ... (This data preparation loop is unchanged) ...\n    for record in dataset_df.to_dict('records'):\n        if weather_aware:\n            dynamic_feats = [record['time_of_day'], record['num_vehicles_on_edge'], record['rain_intensity'],\n                             record['heat_stress'], record['wind_hazard'], record['soil_condition'], record['vehicle_type_truck']]\n        else:\n            dynamic_feats = [record['time_of_day'], record['num_vehicles_on_edge'], record['vehicle_type_truck']]\n        dynamic_edge_features = torch.tensor(dynamic_feats, dtype=torch.float).repeat(site_graph.number_of_edges(), 1)\n        edge_attr = torch.cat([static_edge_features, dynamic_edge_features], dim=1)\n        y = torch.tensor([[record['mean_travel_time'], record['variance']]], dtype=torch.float)\n        u, v = node_mapping[record['edge_start_node']], node_mapping[record['edge_end_node']]\n        data = Data(x=torch.eye(len(node_mapping)), edge_index=edge_index, edge_attr=edge_attr,\n                    y=y, edge_label_index=torch.tensor([[u],[v]], dtype=torch.long))\n        pyg_data_list.append(data)\n\n    # Use PyG's DataLoader, which is optimized for graph data\n    train_size = int(0.8 * len(pyg_data_list))\n    # Increase batch size for multi-GPU training to ensure all GPUs get work\n    batch_size = 32 * torch.cuda.device_count() if torch.cuda.is_available() and torch.cuda.device_count() > 0 else 32\n    train_loader = DataLoader(pyg_data_list[:train_size], batch_size=batch_size, shuffle=True)\n\n    # 3. Instantiate model, optimizer, and loss function\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') # Use cuda:0 as the primary device\n    print(f\"Primary device: {device}\")\n\n    edge_channels = pyg_data_list[0].edge_attr.shape[1]\n    model = EdgePredictorGAT(len(node_mapping), edge_channels, 64)\n    model = model.to(device) # Move the base model to the primary GPU first\n\n    ### MODIFICATION ###\n    # Check if multiple GPUs are available and wrap the model\n    if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n        num_gpus = torch.cuda.device_count()\n        print(f\"Using {num_gpus} GPUs for training!\")\n        model = DataParallel(model) # Wrap the model\n    ### END MODIFICATION ###\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n    def nll_loss(y_true_mean, y_true_var, y_pred_mean, y_pred_var):\n        epsilon = 1e-6\n        loss = torch.log(y_pred_var + epsilon) + ((y_true_mean - y_pred_mean)**2 / (y_pred_var + epsilon))\n        return torch.mean(loss)\n\n    # 4. Training Loop\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        for data in train_loader:\n            # DataParallel automatically handles moving data to the correct devices.\n            # We just need to move the initial batch to the primary device.\n            data = data.to(device)\n            optimizer.zero_grad()\n            pred_mean, pred_var = model(data.x, data.edge_index, data.edge_attr, data.edge_label_index)\n            loss = nll_loss(data.y[:, 0], data.y[:, 1], pred_mean.squeeze(), pred_var.squeeze())\n\n            # If using DataParallel, loss is a tensor on the primary device, but might have a grad_fn\n            # that spans GPUs. Backward() handles this automatically.\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item() * data.num_graphs\n\n        if epoch % 20 == 0:\n            print(f'Epoch: {epoch:02d}, NLL Loss: {total_loss / len(train_loader.dataset):.4f}')\n\n    print(f\"‚úÖ GNN Training Complete for {gnn_type} (Weather-Aware: {weather_aware}).\")\n    \n    ### MODIFICATION ###\n    # If the model was wrapped, unwrap it to get the original model back\n    # This is important for saving the model or using it for inference later.\n    final_model = model.module if isinstance(model, DataParallel) else model\n    ### END MODIFICATION ###\n\n    # Return model on CPU for easier use in the optimizer parts of the code\n    return final_model.to(torch.device('cpu')), node_mapping, static_edge_features, edge_index\n\n# --- Execution: Train the primary and baseline GNN models ---\n# This part of the code remains the same. The function call is identical.\n# The train_gnn_model function will now handle the multi-GPU logic internally.\ngnn_model_aware, node_map, static_feats, edge_idx = train_gnn_model(gnn_type='GAT', weather_aware=True, epochs=51)\ngnn_model_agnostic, _, _, _ = train_gnn_model(gnn_type='GAT', weather_aware=False, epochs=51)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom deap import base, creator, tools, algorithms\nimport random\nimport copy\nfrom math import sqrt\nimport networkx as nx\nfrom datetime import timedelta\n\n# --- Global Configuration for this Optimizer ---\n# This parameter controls how much the optimizer penalizes uncertainty when calculating a single cost score.\nRISK_AVERSION_LAMBDA = 0.5\n\n# --- 1. GNN Prediction Bridge ---\n# This is the same bridge function used by both single- and multi-objective optimizers.\ndef predict_travel_time_with_gnn(u_node, v_node, arrival_time, weather_df, gnn_model,\n                                 vehicle_type, soil_condition, weather_aware=True):\n    \"\"\"\n    Queries the trained GNN model to predict travel time and variance for a single edge.\n    This function acts as the bridge between the optimizer and the ML model.\n    \"\"\"\n    gnn_model.eval()\n    with torch.no_grad():\n        weather = get_weather_at_time(arrival_time, weather_df)\n        if weather_aware:\n            dynamic_feats = [arrival_time.hour, 0, weather['rain_intensity'], weather['heat_stress'],\n                             weather['wind_hazard'], soil_condition, 1 if vehicle_type=='truck' else 0]\n        else:\n            dynamic_feats = [arrival_time.hour, 0, 1 if vehicle_type=='truck' else 0]\n\n        dynamic_features = torch.tensor(dynamic_feats, dtype=torch.float).repeat(site_graph.number_of_edges(), 1)\n        edge_attr = torch.cat([static_feats, dynamic_features], dim=1)\n        u_idx, v_idx = node_map[u_node], node_map[v_node]\n\n        data = Data(x=torch.eye(len(node_map)), edge_index=edge_idx, edge_attr=edge_attr,\n                    edge_label_index=torch.tensor([[u_idx],[v_idx]], dtype=torch.long))\n\n        pred_mean, pred_var = gnn_model(data.x, data.edge_index, data.edge_attr, data.edge_label_index)\n        return pred_mean.item(), pred_var.item()\n\n# --- 2. Fitness Evaluation Function for Single-Objective GA ---\ndef get_path_cost_risk_aware(path, start_time, weather_df, gnn_model, vehicle_type, weather_aware):\n    \"\"\"Calculates the total risk-adjusted cost for a sequence of edges (a path).\"\"\"\n    total_mean_time, total_variance, current_time = 0, 0, start_time\n    for i in range(len(path) - 1):\n        u, v = path[i], path[i+1]\n        edge_data = site_graph.edges[u,v]\n\n        weather = get_weather_at_time(current_time, weather_df)\n        soil = 2 if not edge_data['paved'] and weather['rain_intensity'] > 1 else 0\n\n        mean_time, variance = predict_travel_time_with_gnn(u, v, current_time, weather_df, gnn_model,\n                                                           vehicle_type, soil, weather_aware)\n        total_mean_time += mean_time\n        total_variance += variance\n        current_time += timedelta(seconds=mean_time)\n\n    # The core of risk-aware cost: combine mean time and a penalty for uncertainty (stdev)\n    risk_adjusted_cost = total_mean_time + RISK_AVERSION_LAMBDA * sqrt(total_variance)\n    return risk_adjusted_cost, current_time\n\ndef evaluate_solution_risk_aware(individual, jobs, states, weather_forecast, gnn, graph, weather_aware):\n    \"\"\"\n    The fitness function for the single-objective GA. It evaluates a complete plan (an 'individual')\n    and returns a single cost value. Lower is better.\n    \"\"\"\n    total_cost = 0\n    vehicles = copy.deepcopy(states)\n    job_map = {job['id']: job for job in jobs}\n\n    vehicle_routes = [[] for _ in vehicles]\n    for i, job_id in enumerate(individual):\n        vehicle_routes[i % len(vehicles)].append(job_map[job_id])\n\n    for i, route in enumerate(vehicle_routes):\n        vehicle = vehicles[i]\n        current_loc = vehicle['location']\n        current_time = vehicle['available_time']\n\n        for job in route:\n            path_to_source = nx.shortest_path(graph, source=current_loc, target=job['source'], weight='length')\n            cost_s, time_at_source = get_path_cost_risk_aware(path_to_source, current_time, weather_forecast, gnn, vehicle['type'], weather_aware)\n\n            path_to_dest = nx.shortest_path(graph, source=job['source'], target=job['destination'], weight='length')\n            cost_d, time_at_dest = get_path_cost_risk_aware(path_to_dest, time_at_source, weather_forecast, gnn, vehicle['type'], weather_aware)\n\n            total_cost += cost_s + cost_d\n            current_loc = job['destination']\n            current_time = time_at_dest\n\n    return (total_cost,) # DEAP requires the fitness to be a tuple\n\n# --- 3. Genetic Algorithm Optimizer ---\n# Clean up any existing DEAP classes to allow for fresh definition\nif hasattr(creator, \"FitnessMin\"): del creator.FitnessMin\nif hasattr(creator, \"Individual\"): del creator.Individual\n\ncreator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\ncreator.create(\"Individual\", list, fitness=creator.FitnessMin)\n\ndef run_ga_optimizer(jobs, states, weather_forecast, gnn_model, graph, weather_aware=True):\n    \"\"\"\n    Sets up and runs the single-objective Genetic Algorithm to find the best job permutation\n    based on a risk-adjusted time cost.\n    \"\"\"\n    print(f\"--- Running Optimizer: Single-Objective GA (GNN: {gnn_model is not None}, Weather-Aware: {weather_aware}) ---\")\n    toolbox = base.Toolbox()\n\n    job_ids = [job['id'] for job in jobs]\n    toolbox.register(\"indices\", random.sample, job_ids, len(job_ids))\n    toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.indices)\n    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n    toolbox.register(\"evaluate\", evaluate_solution_risk_aware, jobs=jobs, states=states,\n                     weather_forecast=weather_forecast, gnn=gnn_model, graph=graph, weather_aware=weather_aware)\n    toolbox.register(\"mate\", tools.cxOrdered)\n    toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.05)\n    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n\n    pop = toolbox.population(n=80) # Use a slightly larger population for the complex problem\n    hof = tools.HallOfFame(1)\n    algorithms.eaSimple(pop, toolbox, cxpb=0.7, mutpb=0.2, ngen=60, halloffame=hof, verbose=False)\n\n    best_solution_ids = list(hof[0])\n    plan = [[] for _ in states]\n    for i, job_id in enumerate(best_solution_ids):\n        plan[i % len(states)].append(job_id)\n\n    print(\"‚úÖ GA optimization complete.\")\n    return plan, best_solution_ids\n\n# --- 4. Static Baseline Optimizer (Unchanged) ---\ndef run_static_optimizer(jobs, states, graph):\n    \"\"\"\n    A simple, non-intelligent baseline optimizer. It assigns jobs in a fixed\n    round-robin order without considering any dynamic factors.\n    \"\"\"\n    print(\"--- Running Optimizer: Static Baseline (Round-Robin) ---\")\n    job_ids = sorted([j['id'] for j in jobs])\n    plan = [[] for _ in states]\n    for i, job_id in enumerate(job_ids):\n        plan[i % len(states)].append(job_id)\n    print(\"‚úÖ Static optimization complete.\")\n    return plan, job_ids","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from deap import base, creator, tools, algorithms\nimport networkx as nx\nfrom datetime import timedelta\nimport copy\nfrom math import sqrt\n\n# --- 1. SETUP FOR MULTI-OBJECTIVE OPTIMIZATION (DEAP) ---\n# We define a new fitness class that seeks to minimize all three objectives simultaneously.\n# The weights are negative because DEAP's evolutionary algorithms are typically set up to maximize.\nif hasattr(creator, \"FitnessMulti\"):\n    del creator.FitnessMulti\nif hasattr(creator, \"IndividualMulti\"):\n    del creator.IndividualMulti\n\ncreator.create(\"FitnessMulti\", base.Fitness, weights=(-1.0, -1.0, -1.0)) # Corresponds to (Time, Cost, Risk)\ncreator.create(\"IndividualMulti\", list, fitness=creator.FitnessMulti)\n\n# --- 2. MULTI-OBJECTIVE FITNESS EVALUATION FUNCTIONS ---\n# --- CORRECTED MULTI-OBJECTIVE PATH COST FUNCTION ---\n\ndef get_path_cost_multi_objective(path, start_time, weather_df, gnn_model, vehicle_type, graph):\n    \"\"\"\n    Calculates the three objective costs for a single path (sequence of edges).\n    This function is the core evaluation unit for a vehicle's task.\n    Returns: (total_time, total_variance, total_fuel, end_time)\n    \"\"\"\n    total_time, total_variance, total_fuel = 0, 0, 0\n    current_time = start_time\n    for i in range(len(path) - 1):\n        u, v = path[i], path[i+1]\n        \n        # --- THIS IS THE FIX ---\n        # We must explicitly create a dictionary that includes the start and end nodes,\n        # as the downstream physics function requires them for closure checks.\n        edge_data = {**graph.edges[u,v], 'start_node': u, 'end_node': v}\n        # ---------------------\n\n        weather = get_weather_at_time(current_time, weather_df)\n        soil = 2 if not edge_data['paved'] and weather['rain_intensity'] > 1 else 0\n\n        # Objective 1 & 3 (Time & Risk) are predicted by the GNN\n        pred_mean, pred_var = predict_travel_time_with_gnn(\n            u, v, current_time, weather_df, gnn_model, vehicle_type, soil, weather_aware=True)\n\n        # Objective 2 (Cost/Fuel) is estimated by the physics engine using the GNN's predicted time\n        _, _, fuel = calculate_ground_truth_travel(\n            edge_data, 1, weather, vehicle_type, current_time, soil)\n\n        total_time += pred_mean\n        total_variance += pred_var\n        total_fuel += fuel\n        current_time += timedelta(seconds=pred_mean) # Update clock for the next leg\n\n    return total_time, total_variance, total_fuel, current_time\n    \ndef evaluate_multi_objective(individual, jobs, states, weather, gnn, graph):\n    \"\"\"\n    The main fitness function for NSGA-II. It takes a complete plan ('individual') and\n    returns a tuple of the three objective values: (total_makespan, total_fuel, total_risk).\n    \"\"\"\n    job_map = {job['id']: job for job in jobs}\n    # Create a deep copy of states to avoid modifying the original list\n    vehicles = copy.deepcopy(states)\n\n    # Assign jobs to vehicles based on the permutation in the individual\n    vehicle_routes = [[] for _ in vehicles]\n    for i, job_id in enumerate(individual):\n        vehicle_routes[i % len(vehicles)].append(job_map[job_id])\n\n    # Initialize objective counters\n    vehicle_finish_times = [v['available_time'] for v in vehicles]\n    total_fuel_cost = 0\n    total_risk_score = 0 # Using sum of variances as a proxy for total plan uncertainty\n\n    # Evaluate each vehicle's assigned route\n    for i, route in enumerate(vehicle_routes):\n        vehicle = vehicles[i]\n        current_loc = vehicle['location']\n        current_time = vehicle_finish_times[i]\n\n        for job in route:\n            # Path 1: From current location to job source\n            path_s = nx.shortest_path(graph, source=current_loc, target=job['source'], weight='length')\n            time_s, var_s, fuel_s, time_at_source = get_path_cost_multi_objective(path_s, current_time, weather, gnn, vehicle['type'], graph)\n\n            # Path 2: From job source to job destination\n            path_d = nx.shortest_path(graph, source=job['source'], target=job['destination'], weight='length')\n            time_d, var_d, fuel_d, time_at_dest = get_path_cost_multi_objective(path_d, time_at_source, weather, gnn, vehicle['type'], graph)\n\n            total_fuel_cost += fuel_s + fuel_d\n            total_risk_score += var_s + var_d\n            current_loc = job['destination']\n            current_time = time_at_dest\n\n        # Update this vehicle's final finish time\n        vehicle_finish_times[i] = current_time\n\n    # Objective 1: Makespan is the time the last vehicle finishes its last job\n    final_finish_time = max(vehicle_finish_times)\n    makespan_seconds = (final_finish_time - states[0]['available_time']).total_seconds()\n\n    # Return the three objectives as a tuple, which DEAP will assign to the individual's fitness\n    return makespan_seconds / 3600.0, total_fuel_cost, total_risk_score\n\n# --- 3. NSGA-II OPTIMIZER FUNCTION ---\ndef run_nsga2_optimizer(jobs, states, weather, gnn, graph):\n    \"\"\"\n    Sets up and runs the NSGA-II multi-objective algorithm.\n    \"\"\"\n    print(\"--- Running Optimizer: Multi-Objective NSGA-II ---\")\n    toolbox = base.Toolbox()\n\n    # Define genetic operators for individuals that are lists of job IDs\n    job_ids = [job['id'] for job in jobs]\n    toolbox.register(\"indices\", random.sample, job_ids, len(job_ids))\n    toolbox.register(\"individual\", tools.initIterate, creator.IndividualMulti, toolbox.indices)\n    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n\n    # Register the multi-objective evaluation function\n    toolbox.register(\"evaluate\", evaluate_multi_objective, jobs=jobs, states=states, weather=weather, gnn=gnn, graph=graph)\n\n    # Register the genetic operators\n    toolbox.register(\"mate\", tools.cxOrdered)\n    toolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.05)\n    toolbox.register(\"select\", tools.selNSGA2) # Use the specific NSGA-II selection operator\n\n    # Run the algorithm\n    # Use a larger population and more generations for better exploration of the trade-off space\n    pop = toolbox.population(n=100)\n    hof = tools.ParetoFront() # The Hall of Fame object stores the non-dominated solutions (the Pareto front)\n\n    # Use a standard evolutionary algorithm structure compatible with NSGA-II\n    # mu = population size, lambda_ = number of children to produce each generation\n    algorithms.eaMuPlusLambda(pop, toolbox, mu=100, lambda_=100, cxpb=0.7, mutpb=0.2, ngen=70,\n                               stats=None, halloffame=hof, verbose=False)\n\n    print(f\"‚úÖ NSGA-II optimization complete. Found {len(hof)} optimal trade-off solutions on the Pareto front.\")\n    return hof # Return the entire Pareto front for analysis and visualization","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import copy\nfrom datetime import datetime, timedelta\nimport networkx as nx\n\ndef run_adaptive_simulation(initial_plan_ids, jobs, initial_states, graph, ground_truth_weather,\n                            optimizer_func, gnn_model, weather_aware, events):\n    \"\"\"\n    Simulates the real-time execution of a logistics plan, reacting to events by re-planning.\n    This is the core of the \"Digital Twin\" functionality.\n    \"\"\"\n    re_planning_enabled = optimizer_func is not None\n    model_name = \"Adaptive\" if re_planning_enabled else \"Static Plan\"\n    print(f\"\\nüöÄ LAUNCHING SIMULATION ({model_name} Mode) üöÄ\")\n\n    # --- Simulation State Initialization ---\n    vehicles = copy.deepcopy(initial_states)\n    for v in vehicles:\n        v.update({'status': 'idle', 'path': [], 'edge_finish_time': None, 'current_job': None})\n\n    job_map = {j['id']: j for j in jobs}\n    job_queues = {v['id']: [] for v in vehicles}\n    for i, job_id in enumerate(initial_plan_ids):\n        vehicle_id = vehicles[i % len(vehicles)]['id']\n        job_queues[vehicle_id].append(job_map[job_id])\n\n    completed_jobs = set()\n    current_time = initial_states[0]['available_time']\n    time_step = timedelta(seconds=60) # Use a slightly larger time step for faster simulation\n    active_edge_usage = {(u, v): 0 for u, v in graph.edges()}\n    system_graph = graph\n    system_forecast = ground_truth_weather[current_time : current_time + timedelta(hours=8)]\n\n    # --- Event Tracking ---\n    events.sort(key=lambda e: e['time'])\n    next_event_idx = 0\n\n    # --- Main Simulation Loop ---\n    while len(completed_jobs) < len(jobs):\n        # 1. EVENT TRIGGER CHECK (Logic is unchanged)\n        if re_planning_enabled and next_event_idx < len(events) and current_time >= events[next_event_idx]['time']:\n            event = events[next_event_idx]\n            print(f\"\\nüîî EVENT @ {current_time.strftime('%H:%M:%S')}: {event['description']} üîî\")\n            next_event_idx += 1\n            if 'forecast_update' in event: system_forecast = event['forecast_update']\n            if 'graph_update' in event: system_graph = event['graph_update']\n            \n            print(\"   ‚ñ∂ Pausing simulation for autonomous re-planning...\")\n            in_progress_jobs = {v['current_job']['id'] for v in vehicles if v.get('current_job')}\n            queued_jobs = [job for queue in job_queues.values() for job in queue]\n            jobs_to_replan = [job for job in queued_jobs if job['id'] not in in_progress_jobs]\n            \n            if jobs_to_replan:\n                for v in vehicles: v['available_time'] = current_time\n                _, new_plan_ids = optimizer_func(jobs_to_replan, vehicles, system_forecast, gnn_model, system_graph, weather_aware)\n                for q in job_queues.values(): q.clear()\n                for i, job_id in enumerate(new_plan_ids):\n                    vehicle_id = vehicles[i % len(vehicles)]['id']\n                    job_queues[vehicle_id].append(job_map[job_id])\n                print(f\"   ‚úÖ New plan with {len(new_plan_ids)} jobs adopted. Resuming simulation.\")\n            else:\n                print(\"   ...No queued jobs to replan. Resuming simulation.\")\n            print(\"-\" * 30)\n\n        # 2. VEHICLE STATE MACHINE LOGIC\n        for v in vehicles:\n            if v['status'] == 'moving_on_edge' and current_time >= v['edge_finish_time']:\n                prev_edge = (v['path'][0], v['path'][1])\n                active_edge_usage[prev_edge] = max(0, active_edge_usage[prev_edge] - 1)\n                v['location'] = v['path'][1]\n                v['path'] = v['path'][1:]\n                v['status'] = 'en_route'\n                v['edge_finish_time'] = None\n\n        for v in vehicles:\n            if v['status'] in ['idle', 'en_route'] and len(v.get('path', [])) <= 1:\n                v['path'] = []\n                if v.get('current_job') and v['location'] == v['current_job']['destination']:\n                    completed_jobs.add(v['current_job']['id'])\n                    v['current_job'] = None\n                if not v.get('current_job') and job_queues[v['id']]:\n                    v['current_job'] = job_queues[v['id']].pop(0)\n                    v['path'] = nx.shortest_path(system_graph, source=v['location'], target=v['current_job']['source'], weight='length')\n                    v['status'] = 'en_route'\n                elif v.get('current_job') and v['location'] == v['current_job']['source']:\n                    v['path'] = nx.shortest_path(system_graph, source=v['location'], target=v['current_job']['destination'], weight='length')\n                    v['status'] = 'en_route'\n                else:\n                    v['status'] = 'idle'\n        \n        for v in vehicles:\n            if v['status'] == 'en_route' and len(v['path']) > 1:\n                u, next_node = v['path'][0], v['path'][1]\n                edge = (u, next_node)\n                if not graph.has_edge(u, next_node):\n                    v['status'] = 'blocked'\n                    continue\n\n                edge_data = {**graph.edges[edge], 'start_node': u, 'end_node': next_node}\n                weather_now = get_weather_at_time(current_time, ground_truth_weather)\n                soil = 0\n                if not edge_data['paved'] and weather_now['rain_intensity'] > 1: soil=2\n                \n                # --- THIS IS THE CORRECTED LINE ---\n                # FIX 1: Use the new function name: calculate_ground_truth_travel\n                # FIX 2: Unpack all three return values, even if we only use the first one here.\n                mean_time, _, _ = calculate_ground_truth_travel(edge_data, active_edge_usage[edge], weather_now, v['type'], current_time, soil)\n                # ------------------------------------\n\n                v['status'] = 'moving_on_edge'\n                v['edge_finish_time'] = current_time + timedelta(seconds=mean_time)\n                active_edge_usage[edge] += 1\n\n        # 3. ADVANCE SIMULATION CLOCK\n        current_time += time_step\n        if current_time > initial_states[0]['available_time'] + timedelta(hours=24):\n            print(f\"üõë SIMULATION TIMEOUT after 24 hours. {len(completed_jobs)}/{len(jobs)} jobs completed.\")\n            break\n\n    # Calculate final makespan\n    last_finish_time = max([v['edge_finish_time'] for v in vehicles if v.get('edge_finish_time')] + [current_time])\n    makespan = (last_finish_time - initial_states[0]['available_time']).total_seconds() / 3600.0\n    print(f\"üèÅ Simulation Finished. Makespan: {makespan:.2f} Hours\")\n    return makespan","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport matplotlib.pyplot as plt\nimport copy\n\n# --- 1. EXPERIMENT SETUP FOR THE COMPLEX SCENARIO ---\n# For reproducibility, set a random seed\nrandom.seed(42)\n\n# --- Define a more diverse and realistic vehicle fleet ---\nINITIAL_VEHICLE_STATES = [\n    {\n        'id': 0, 'type': 'truck', 'location': 'Main_Gate',\n        'available_time': SIMULATION_START_TIME\n    },\n    {\n        'id': 1, 'type': 'truck', 'location': 'Contractor_Gate',\n        'available_time': SIMULATION_START_TIME\n    },\n    {\n        'id': 2, 'type': 'forklift', 'location': 'Laydown_A',\n        'available_time': SIMULATION_START_TIME\n    },\n]\n\n# --- Define a complex list of jobs that use the new, specialized nodes ---\n# A full implementation would require modifying the optimizer to handle multi-stop\n# sequences and vehicle requirements. For this runnable example, we simplify by\n# breaking multi-stop jobs into a series of single-leg tasks.\nCOMPLEX_JOBS = [\n    {'task': 'Deliver Rebar', 'sequence': [('Laydown_A', 'Building_1_N')]},\n    {'task': 'Clear Debris from Pit', 'sequence': [('Foundation_Pit', 'Waste_Disposal')]},\n    {'task': 'Move Scaffolding', 'sequence': [('Laydown_B', 'Building_2_W')]},\n    {'task': 'Prefab Wall Delivery', 'sequence': [('Fabrication_Yard', 'Building_1_S')]},\n    {'task': 'Multi-stop Debris Clearance', 'sequence': [('Building_1_S', 'Waste_Disposal'), ('Building_2_E', 'Waste_Disposal')]},\n    {'task': 'Small Tool Delivery', 'sequence': [('Laydown_A', 'Foundation_Pit')]},\n    {'task': 'Deliver piping', 'sequence': [('Laydown_A', 'Building_2_W')]},\n    {'task': 'Move excess soil', 'sequence': [('Foundation_Pit', 'Waste_Disposal')]},\n    {'task': 'Transport fabricated component', 'sequence': [('Fabrication_Yard', 'Building_2_E')]}\n]\n\n# Flatten the complex jobs into a simple list that our current optimizer can handle\nJOBS_FOR_PLANNING = []\njob_counter = 0\nfor job in COMPLEX_JOBS:\n    for u, v in job['sequence']:\n        JOBS_FOR_PLANNING.append({'id': job_counter, 'source': u, 'destination': v})\n        job_counter += 1\n\nprint(f\"‚úÖ Complex scenario defined with {len(INITIAL_VEHICLE_STATES)} vehicles and {len(JOBS_FOR_PLANNING)} total tasks.\")\n\n# --- 2. DEFINE THE GROUND TRUTH SCENARIO WITH NEW DISRUPTIONS ---\nINITIAL_FORECAST = weather_df[SIMULATION_START_TIME : SIMULATION_START_TIME + timedelta(hours=8)]\n\n# The actual weather includes a surprise storm\nground_truth_weather = weather_df.copy()\nstorm_start = SIMULATION_START_TIME + timedelta(hours=2)\nstorm_end = SIMULATION_START_TIME + timedelta(hours=4) # A longer storm\nground_truth_weather.loc[storm_start:storm_end, 'rain'] = 8.0\nground_truth_weather.loc[storm_start:storm_end, 'rain_intensity'] = 3\nprint(f\"Disruption 1: A surprise storm will occur between {storm_start.strftime('%H:%M')} and {storm_end.strftime('%H:%M')}.\")\n\n# The new forecast, revealing the storm, becomes available at T+45min\nupdated_forecast = ground_truth_weather[SIMULATION_START_TIME : SIMULATION_START_TIME + timedelta(hours=8)]\n\n# A critical path on the main circulation loop is blocked by a crane at T+3h\nbroken_down_graph = site_graph.copy()\nblocked_edge = ('Building_1_S', 'Main_Gate')\nif broken_down_graph.has_edge(*blocked_edge):\n    broken_down_graph.remove_edge(*blocked_edge)\n    print(f\"Disruption 2: Path '{blocked_edge[0]}'->'{blocked_edge[1]}' will be blocked at { (SIMULATION_START_TIME + timedelta(hours=3)).strftime('%H:%M') }.\")\n\n# Package disruptions into a list of events for the adaptive simulation\nsimulation_events = [\n    {\n        'time': SIMULATION_START_TIME + timedelta(minutes=45),\n        'description': \"Weather Forecast Update: Major Storm Predicted!\",\n        'forecast_update': updated_forecast\n    },\n    {\n        'time': SIMULATION_START_TIME + timedelta(hours=3),\n        'description': \"Site Disruption: Main Gate Access Route Blocked!\",\n        'graph_update': broken_down_graph\n    }\n]\n\n# --- 3. RUN ALL MODELS AGAINST THE COMPLEX SCENARIO ---\nresults = {}\n\n# --- Model 1: Static Baseline ---\nstatic_plan, static_plan_ids = run_static_optimizer(JOBS_FOR_PLANNING, INITIAL_VEHICLE_STATES, site_graph)\nresults['Static Baseline'] = run_adaptive_simulation(\n    static_plan_ids, JOBS_FOR_PLANNING, INITIAL_VEHICLE_STATES, site_graph, ground_truth_weather,\n    optimizer_func=None, gnn_model=None, weather_aware=False, events=simulation_events)\n\n# --- Model 2: Weather-Agnostic GNN (Static Plan) ---\nagnostic_plan, agnostic_plan_ids = run_ga_optimizer(JOBS_FOR_PLANNING, INITIAL_VEHICLE_STATES, INITIAL_FORECAST, gnn_model_agnostic, site_graph, weather_aware=False)\nresults['GA-GNN (Agnostic, Static)'] = run_adaptive_simulation(\n    agnostic_plan_ids, JOBS_FOR_PLANNING, INITIAL_VEHICLE_STATES, site_graph, ground_truth_weather,\n    optimizer_func=None, gnn_model=gnn_model_agnostic, weather_aware=False, events=simulation_events)\n\n# --- Model 3: Weather-Aware GNN (Static Plan) ---\naware_plan_static, aware_plan_static_ids = run_ga_optimizer(JOBS_FOR_PLANNING, INITIAL_VEHICLE_STATES, INITIAL_FORECAST, gnn_model_aware, site_graph, weather_aware=True)\nresults['GA-GNN (Aware, Static)'] = run_adaptive_simulation(\n    aware_plan_static_ids, JOBS_FOR_PLANNING, INITIAL_VEHICLE_STATES, site_graph, ground_truth_weather,\n    optimizer_func=None, gnn_model=gnn_model_aware, weather_aware=True, events=simulation_events)\n\n# --- Model 4: Single-Objective Adaptive Digital Twin ---\nresults['GA-GNN (Aware, Adaptive)'] = run_adaptive_simulation(\n    aware_plan_static_ids, JOBS_FOR_PLANNING, INITIAL_VEHICLE_STATES, site_graph, ground_truth_weather,\n    optimizer_func=run_ga_optimizer, gnn_model=gnn_model_aware, weather_aware=True, events=simulation_events)\n\n# --- NEW MODEL 5: MULTI-OBJECTIVE ADAPTIVE DIGITAL TWIN (THE CHAMPION) ---\nprint(\"\\n--- Generating Initial Plan from Pareto Front ---\")\n# Find the \"Fastest\" plan from the Pareto front generated earlier to use as our initial plan.\n# If the pareto_front is not yet generated, run the optimizer now.\nif 'pareto_front' not in locals():\n    pareto_front = run_nsga2_optimizer(JOBS_FOR_PLANNING, INITIAL_VEHICLE_STATES, INITIAL_FORECAST, gnn_model_aware, site_graph)\n\nif pareto_front:\n    solutions = np.array([list(ind.fitness.values) for ind in pareto_front])\n    fastest_idx = np.argmin(solutions[:, 0])\n    # This is the list of job IDs for the fastest plan.\n    fastest_plan_ids = list(pareto_front[fastest_idx])\n    print(f\"Selected 'Fastest' plan from Pareto front as the initial plan.\")\n\n    # Define a wrapper function for re-planning that matches the expected signature\n    def replan_with_nsga2_fastest(jobs, states, weather, gnn, graph, weather_aware):\n        # The adaptive simulation harness needs a function that returns a single best plan.\n        # This wrapper runs NSGA-II and selects the \"fastest\" plan from the new Pareto front.\n        hof = run_nsga2_optimizer(jobs, states, weather, gnn, graph)\n        if not hof: return [], [] # Return empty if no solution found\n        new_solutions = np.array([list(ind.fitness.values) for ind in hof])\n        new_fastest_idx = np.argmin(new_solutions[:, 0])\n        best_plan_ids = list(hof[new_fastest_idx])\n        # The optimizer function is expected to return (plan, plan_ids)\n        dummy_plan = [[] for _ in states]\n        for i, job_id in enumerate(best_plan_ids):\n            dummy_plan[i % len(states)].append(job_id)\n        return dummy_plan, best_plan_ids\n\n    results['Multi-Obj (Fastest, Adaptive)'] = run_adaptive_simulation(\n        fastest_plan_ids, JOBS_FOR_PLANNING, INITIAL_VEHICLE_STATES, site_graph, ground_truth_weather,\n        optimizer_func=replan_with_nsga2_fastest, gnn_model=gnn_model_aware, weather_aware=True, events=simulation_events)\nelse:\n    print(\"WARNING: Pareto front is empty. Skipping Multi-Objective Champion model.\")\n\n\n# --- 4. ANALYZE AND PLOT FINAL RESULTS ---\nsorted_results = sorted(results.items(), key=lambda item: item[1])\nprint(\"\\n\\n\" + \"=\"*60); print(\"--- üìä FINAL PERFORMANCE COMPARISON üìä ---\"); print(\"=\"*60)\nfor name, makespan in sorted_results:\n    print(f\"{name:<35}: {makespan:.2f} Hours\")\nprint(\"=\"*60)\n\nlabels = [name for name, score in sorted_results]\nscores = [score for name, score in sorted_results]\ncolors = ['grey', 'lightcoral', 'skyblue', 'darkorange', 'forestgreen'] # Added new colors\n\nplt.figure(figsize=(14, 8))\nbars = plt.barh(labels, scores, color=colors[:len(labels)])\nplt.xlabel(\"Total Project Makespan (Hours)\"); plt.ylabel(\"Planning & Control Model\")\nplt.title(\"Figure: Final Model Performance in Disrupted Scenario\", fontsize=16)\nplt.gca().invert_yaxis(); plt.tight_layout()\n\nfor i, bar in enumerate(bars):\n    width = bar.get_width()\n    plt.text(width + 0.05, bar.get_y() + bar.get_height()/2, f'{width:.2f} hrs', ha='left', va='center', fontsize=11, weight='bold')\n\ntry:\n    baseline_score = results['GA-GNN (Aware, Static)']\n    champion_score = results['Multi-Obj (Fastest, Adaptive)']\n    improvement = ((baseline_score - champion_score) / baseline_score) * 100\n    print(f\"\\nüèÜ The adaptive multi-objective model showed a {improvement:.2f}% improvement over the best static plan.\")\nexcept (KeyError, ZeroDivisionError):\n    print(\"\\nCould not calculate final improvement metric.\")\n\nplt.xlim(right=max(scores) * 1.20)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport matplotlib.pyplot as plt\nimport copy\nimport torch\nimport numpy as np\n\n# --- 0. PRE-REQUISITE: ENSURE MODELS AND TENSORS ARE ON GPU ---\n# This part is crucial. It should be run after GNN training (Chunk 5) and before this chunk.\n# It prepares all the necessary components for fast GPU-based optimization.\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"--- Preparing for CUDA-based Experiment on device: {device} ---\")\n\n# Move GNN models to the specified device\ngnn_model_aware.to(device)\ngnn_model_agnostic.to(device)\n\n# Move static graph tensors to the device. These will be reused many times.\nstatic_feats_gpu = static_feats.to(device)\nedge_idx_gpu = edge_idx.to(device)\nnode_identity_gpu = torch.eye(len(node_map)).to(device)\n\n\n# --- 1. EXPERIMENT SETUP (COMPLEX SCENARIO, UNCHANGED) ---\nrandom.seed(42)\n# ... (Vehicle and Job definitions remain the same as the previous complex version) ...\nINITIAL_VEHICLE_STATES = [\n    {'id': 0, 'type': 'truck', 'location': 'Main_Gate', 'available_time': SIMULATION_START_TIME},\n    {'id': 1, 'type': 'truck', 'location': 'Contractor_Gate', 'available_time': SIMULATION_START_TIME},\n    {'id': 2, 'type': 'forklift', 'location': 'Laydown_A', 'available_time': SIMULATION_START_TIME},\n]\nCOMPLEX_JOBS = [\n    {'task': 'Deliver Rebar', 'sequence': [('Laydown_A', 'Building_1_N')]},\n    {'task': 'Clear Debris from Pit', 'sequence': [('Foundation_Pit', 'Waste_Disposal')]},\n    {'task': 'Move Scaffolding', 'sequence': [('Laydown_B', 'Building_2_W')]},\n    {'task': 'Prefab Wall Delivery', 'sequence': [('Fabrication_Yard', 'Building_1_S')]},\n    {'task': 'Multi-stop Debris Clearance', 'sequence': [('Building_1_S', 'Waste_Disposal'), ('Building_2_E', 'Waste_Disposal')]},\n    {'task': 'Small Tool Delivery', 'sequence': [('Laydown_A', 'Foundation_Pit')]},\n    {'task': 'Deliver piping', 'sequence': [('Laydown_A', 'Building_2_W')]},\n    {'task': 'Move excess soil', 'sequence': [('Foundation_Pit', 'Waste_Disposal')]},\n    {'task': 'Transport fabricated component', 'sequence': [('Fabrication_Yard', 'Building_2_E')]}\n]\nJOBS_FOR_PLANNING = []\njob_counter = 0\nfor job in COMPLEX_JOBS:\n    for u, v in job['sequence']:\n        JOBS_FOR_PLANNING.append({'id': job_counter, 'source': u, 'destination': v})\n        job_counter += 1\n\nprint(f\"‚úÖ Complex scenario defined with {len(INITIAL_VEHICLE_STATES)} vehicles and {len(JOBS_FOR_PLANNING)} total tasks.\")\n\n\n# --- 2. DISRUPTION SCENARIO DEFINITION (UNCHANGED) ---\n# ... (Event definitions remain the same) ...\nINITIAL_FORECAST = weather_df[SIMULATION_START_TIME : SIMULATION_START_TIME + timedelta(hours=8)]\nground_truth_weather = weather_df.copy()\nstorm_start = SIMULATION_START_TIME + timedelta(hours=2)\nstorm_end = SIMULATION_START_TIME + timedelta(hours=4)\nground_truth_weather.loc[storm_start:storm_end, 'rain'] = 8.0\nground_truth_weather.loc[storm_start:storm_end, 'rain_intensity'] = 3\nprint(f\"Disruption 1: Surprise storm will occur between {storm_start.strftime('%H:%M')} and {storm_end.strftime('%H:%M')}.\")\n\nupdated_forecast = ground_truth_weather[SIMULATION_START_TIME : SIMULATION_START_TIME + timedelta(hours=8)]\n\nbroken_down_graph = site_graph.copy()\nblocked_edge = ('Building_1_S', 'Main_Gate')\nif broken_down_graph.has_edge(*blocked_edge):\n    broken_down_graph.remove_edge(*blocked_edge)\n    print(f\"Disruption 2: Path '{blocked_edge[0]}'->'{blocked_edge[1]}' will be blocked at { (SIMULATION_START_TIME + timedelta(hours=3)).strftime('%H:%M') }.\")\n\nsimulation_events = [\n    {'time': SIMULATION_START_TIME + timedelta(minutes=45), 'description': \"Weather Forecast Update!\", 'forecast_update': updated_forecast},\n    {'time': SIMULATION_START_TIME + timedelta(hours=3), 'description': \"Path Blockage!\", 'graph_update': broken_down_graph}\n]\n\n\n# --- 3. RUN ALL MODELS AGAINST THE COMPLEX SCENARIO (USING CUDA OPTIMIZERS) ---\nresults = {}\n\n# NOTE: The adaptive simulation harness (Chunk 7) does not need to change.\n# It simply calls whatever optimizer function we pass to it.\n# The `run_static_optimizer` is CPU-only and needs no changes.\n\n# --- Model 1: Static Baseline (CPU) ---\nstatic_plan, static_plan_ids = run_static_optimizer(JOBS_FOR_PLANNING, INITIAL_VEHICLE_STATES, site_graph)\nresults['Static Baseline'] = run_adaptive_simulation(\n    static_plan_ids, JOBS_FOR_PLANNING, INITIAL_VEHICLE_STATES, site_graph, ground_truth_weather,\n    optimizer_func=None, gnn_model=None, weather_aware=False, events=simulation_events)\n\n# --- Model 2 & 3: Single-Objective Static Plans (Can use CPU or a future GPU version of GA) ---\n# We'll use the original CPU-based `run_ga_optimizer` for these static, one-off plans, as the overhead\n# of setting up GPU batching for a single run is not always worth it.\naware_plan_static, aware_plan_static_ids = run_ga_optimizer(JOBS_FOR_PLANNING, INITIAL_VEHICLE_STATES, INITIAL_FORECAST, gnn_model_aware.to('cpu'), site_graph, weather_aware=True)\ngnn_model_aware.to(device) # Move model back to GPU for adaptive runs\nresults['GA-GNN (Aware, Static)'] = run_adaptive_simulation(\n    aware_plan_static_ids, JOBS_FOR_PLANNING, INITIAL_VEHICLE_STATES, site_graph, ground_truth_weather,\n    optimizer_func=None, gnn_model=gnn_model_aware, weather_aware=True, events=simulation_events)\n\n\n# --- NEW MODEL 4: MULTI-OBJECTIVE ADAPTIVE DIGITAL TWIN (THE CHAMPION, ON CUDA) ---\nprint(\"\\n--- Generating Initial Plan from Pareto Front using GPU Optimizer ---\")\n\n# Use the fast, GPU-batched NSGA-II optimizer (assuming it's defined in Chunk 6B)\n# If you haven't written the fully batched version, you can use the cached CPU version here.\n# For this example, we assume `run_nsga2_optimizer_gpu` exists.\n# If not, fallback to the CPU version: `run_nsga2_optimizer`\noptimizer_to_use = run_nsga2_optimizer # Fallback to CPU version if GPU one not implemented\nif 'run_nsga2_optimizer_gpu' in locals():\n    optimizer_to_use = run_nsga2_optimizer_gpu\n\npareto_front = optimizer_to_use(JOBS_FOR_PLANNING, INITIAL_VEHICLE_STATES, INITIAL_FORECAST, gnn_model_aware, site_graph)\n\nif pareto_front:\n    solutions = np.array([list(ind.fitness.values) for ind in pareto_front])\n    fastest_idx = np.argmin(solutions[:, 0])\n    fastest_plan_ids = list(pareto_front[fastest_idx])\n    print(f\"Selected 'Fastest' plan from Pareto front as the initial plan.\")\n\n    # Define a wrapper for re-planning that uses the same GPU optimizer\n    def replan_with_nsga2_fastest_gpu(jobs, states, weather, gnn, graph, weather_aware):\n        hof = optimizer_to_use(jobs, states, weather, gnn, graph)\n        if not hof: return [], []\n        new_solutions = np.array([list(ind.fitness.values) for ind in hof])\n        new_fastest_idx = np.argmin(new_solutions[:, 0])\n        best_plan_ids = list(hof[new_fastest_idx])\n        dummy_plan = [[] for _ in states]\n        for i, job_id in enumerate(best_plan_ids):\n            dummy_plan[i % len(states)].append(job_id)\n        return dummy_plan, best_plan_ids\n\n    results['Multi-Obj (Fastest, Adaptive, CUDA)'] = run_adaptive_simulation(\n        fastest_plan_ids, JOBS_FOR_PLANNING, INITIAL_VEHICLE_STATES, site_graph, ground_truth_weather,\n        optimizer_func=replan_with_nsga2_fastest_gpu, gnn_model=gnn_model_aware, weather_aware=True, events=simulation_events)\nelse:\n    print(\"WARNING: Pareto front is empty. Skipping Multi-Objective Champion model.\")\n\n\n# --- 4. ANALYZE AND PLOT FINAL RESULTS ---\n# This part is unchanged as it only deals with the final numbers.\nsorted_results = sorted(results.items(), key=lambda item: item[1])\nprint(\"\\n\\n\" + \"=\"*60); print(\"--- üìä FINAL PERFORMANCE COMPARISON üìä ---\"); print(\"=\"*60)\nfor name, makespan in sorted_results:\n    print(f\"{name:<40}: {makespan:.2f} Hours\")\nprint(\"=\"*60)\n\nlabels = [name for name, score in sorted_results]\nscores = [score for name, score in sorted_results]\ncolors = ['grey', 'skyblue', 'forestgreen'] # Simplified colors\n\nplt.figure(figsize=(14, 8))\nbars = plt.barh(labels, scores, color=colors[:len(labels)])\nplt.xlabel(\"Total Project Makespan (Hours)\"); plt.ylabel(\"Planning & Control Model\")\nplt.title(\"Figure: Final Model Performance in Disrupted Scenario (CUDA Accelerated)\", fontsize=16)\nplt.gca().invert_yaxis(); plt.tight_layout()\n\nfor i, bar in enumerate(bars):\n    width = bar.get_width()\n    plt.text(width + 0.05, bar.get_y() + bar.get_height()/2, f'{width:.2f} hrs', ha='left', va='center', fontsize=11, weight='bold')\n\ntry:\n    baseline_score = results['GA-GNN (Aware, Static)']\n    champion_score = results['Multi-Obj (Fastest, Adaptive, CUDA)']\n    improvement = ((baseline_score - champion_score) / baseline_score) * 100\n    print(f\"\\nüèÜ The CUDA-accelerated adaptive model showed a {improvement:.2f}% improvement over the best static plan.\")\nexcept (KeyError, ZeroDivisionError):\n    print(\"\\nCould not calculate final improvement metric.\")\n\nplt.xlim(right=max(scores) * 1.20 if scores else 1)\nplt.show()\n\n# --- 5. CLEANUP: Move models back to CPU if needed for other tasks ---\ngnn_model_aware.to('cpu')\ngnn_model_agnostic.to('cpu')\nprint(\"\\nModels moved back to CPU.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# --- 1. RUN THE MULTI-OBJECTIVE OPTIMIZER TO GET THE PARETO FRONT ---\n# This function is defined in Chunk 6B. We run it on the initial planning scenario\n# to generate the set of optimal trade-off solutions for analysis.\npareto_front = run_nsga2_optimizer(JOBS_FOR_PLANNING, INITIAL_VEHICLE_STATES, INITIAL_FORECAST, gnn_model_aware, site_graph)\n\n# --- 2. EXTRACT AND ANALYZE THE PARETO SOLUTIONS ---\nif pareto_front:\n    # Extract the fitness values (Time, Cost, Risk) from each non-dominated solution\n    solutions = np.array([list(ind.fitness.values) for ind in pareto_front])\n\n    # Separate the objectives into individual arrays for analysis and plotting\n    times = solutions[:, 0]  # Makespan in Hours\n    costs = solutions[:, 1]  # Total Fuel in Liters\n    risks = solutions[:, 2]  # Sum of Variances (Risk Score)\n\n    # Identify three key representative solutions from the front for discussion\n    # These highlight the extremes of the trade-off space\n    fastest_idx = np.argmin(times)\n    cheapest_idx = np.argmin(costs)\n    safest_idx = np.argmin(risks)\n\n    best_time_solution = solutions[fastest_idx]\n    best_cost_solution = solutions[cheapest_idx]\n    best_risk_solution = solutions[safest_idx]\n\n    print(\"\\n\" + \"=\"*50)\n    print(\"--- Analysis of Representative Optimal Solutions ---\")\n    print(\"=\"*50)\n    print(f\"Fastest Plan (Greedy):\")\n    print(f\"  Makespan: {best_time_solution[0]:.2f} hrs | Fuel Cost: {best_time_solution[1]:.2f} L | Risk Score: {best_time_solution[2]:.2f}\")\n    print(\"\\n\")\n    print(f\"Cheapest Plan (Economical):\")\n    print(f\"  Makespan: {best_cost_solution[0]:.2f} hrs | Fuel Cost: {best_cost_solution[1]:.2f} L | Risk Score: {best_cost_solution[2]:.2f}\")\n    print(\"\\n\")\n    print(f\"Safest Plan (Reliable/Low-Risk):\")\n    print(f\"  Makespan: {best_risk_solution[0]:.2f} hrs | Fuel Cost: {best_risk_solution[1]:.2f} L | Risk Score: {best_risk_solution[2]:.2f}\")\n    print(\"=\"*50)\n\n\n    # --- 3. 3D VISUALIZATION OF THE PARETO FRONT ---\n    fig = plt.figure(figsize=(14, 12))\n    ax = fig.add_subplot(111, projection='3d')\n\n    # Create the 3D scatter plot of all solutions on the Pareto front\n    # The color of each point is mapped to its makespan value for an extra visual cue\n    scatter = ax.scatter(times, costs, risks, c=times, cmap='viridis', s=60, alpha=0.8, edgecolors='k', linewidth=0.5)\n\n    # Highlight the representative solutions with larger markers and labels\n    ax.scatter(best_time_solution[0], best_time_solution[1], best_time_solution[2], c='red', s=200, marker='*', label='Fastest')\n    ax.text(best_time_solution[0]*1.01, best_time_solution[1]*1.01, best_time_solution[2]*1.01, \"Fastest\", color='red', fontsize=12)\n\n    ax.scatter(best_cost_solution[0], best_cost_solution[1], best_cost_solution[2], c='blue', s=200, marker='P', label='Cheapest')\n    ax.text(best_cost_solution[0]*1.01, best_cost_solution[1]*1.01, best_cost_solution[2]*1.01, \"Cheapest\", color='blue', fontsize=12)\n\n    ax.scatter(best_risk_solution[0], best_risk_solution[1], best_risk_solution[2], c='green', s=200, marker='D', label='Safest')\n    ax.text(best_risk_solution[0]*1.01, best_risk_solution[1]*1.01, best_risk_solution[2]*1.01, \"Safest\", color='green', fontsize=12)\n\n    # Set titles and labels for clarity\n    ax.set_title('Pareto Front: Optimal Trade-offs (Time vs. Cost vs. Risk)', fontsize=18, pad=20)\n    ax.set_xlabel('\\nMakespan (Hours) - Lower is Better', fontsize=12)\n    ax.set_ylabel('\\nTotal Fuel (Liters) - Lower is Better', fontsize=12)\n    ax.set_zlabel('\\nLateness Risk Score - Lower is Better', fontsize=12)\n\n    # Invert axes so that the \"best\" point (0,0,0) is visually in the corner, which is more intuitive\n    ax.invert_xaxis()\n    ax.invert_yaxis()\n    ax.invert_zaxis()\n\n    # Add a color bar to explain the color mapping\n    cbar = fig.colorbar(scatter, shrink=0.6, aspect=20, pad=0.01)\n    cbar.set_label('Makespan (Hours)', fontsize=12)\n\n    ax.legend(fontsize=12)\n    plt.show()\n\n    # NOTE: To complete the paper's final experiment, you would now choose one of these plans\n    # (e.g., the 'Fastest Plan') and pass its job sequence to the adaptive simulation harness\n    # in Chunk 8. This would allow you to have a bar on your final chart labeled\n    # \"Adaptive Multi-Objective (Fastest)\", comparing its final makespan against the others.\nelse:\n    print(\"Execution Warning: No solutions were found by the NSGA-II optimizer. The Pareto front is empty.\")\n    print(\"This can happen with very few generations or a very difficult problem. Consider increasing `ngen` in Chunk 6B.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install graphviz if you don't have it\n!pip install graphviz -q\n\nimport graphviz\n\n# Create a new directed graph\ndot = graphviz.Digraph('system_workflow', comment='System Architecture')\ndot.attr(rankdir='TB', label='System Architecture for Adaptive Construction Logistics', labelloc='t', fontsize='20')\n\n# Define styles for different node types\nstyles = {\n    'data': {'shape': 'parallelogram', 'style': 'filled', 'fillcolor': 'lightblue'},\n    'process': {'shape': 'ellipse', 'style': 'filled', 'fillcolor': 'lightgrey'},\n    'model': {'shape': 'box', 'style': 'filled', 'fillcolor': 'lightyellow'},\n    'decision': {'shape': 'diamond', 'style': 'filled', 'fillcolor': 'lightpink'},\n    'output': {'shape': 'folder', 'style': 'filled', 'fillcolor': 'lightgreen'}\n}\n\n# Define the nodes of the flowchart\ndot.node('A', 'Site Layout & 4D Schedule', **styles['data'])\ndot.node('B', 'Historical Weather Data (ERA5)', **styles['data'])\ndot.node('C', 'Synthetic Data Generator (Physics Engine)', **styles['process'])\ndot.node('D', 'Training Dataset (Travel Times & Conditions)', **styles['data'])\ndot.node('E', 'GNN Model Training', **styles['model'])\ndot.node('F', 'Trained Probabilistic GNN (Travel Time Predictor)', **styles['model'])\n\ndot.node('G', 'Real-Time Forecast & Site State', **styles['data'])\ndot.node('H', 'Job List & Vehicle Status', **styles['data'])\ndot.node('I', 'Genetic Algorithm Optimizer', **styles['process'])\ndot.node('J', 'Is Re-planning Triggered?', **styles['decision'])\ndot.node('K', 'Execute Current Plan', **styles['process'])\ndot.node('L', 'Optimized & Adapted Route Plan', **styles['output'])\n\n# Define the edges (connections) between the nodes\ndot.edge('A', 'C')\ndot.edge('B', 'C')\ndot.edge('C', 'D')\ndot.edge('D', 'E')\ndot.edge('E', 'F')\n\n# The core optimization loop\nsubgraph = graphviz.Digraph('cluster_0')\nsubgraph.attr(style='filled', color='whitesmoke', label='Online Digital Twin Operation')\nsubgraph.edge('G', 'J', label='Event (e.g., Forecast Update)')\nsubgraph.edge('H', 'I')\nsubgraph.edge('F', 'I', label='GNN provides\\ncost estimates')\nsubgraph.edge('I', 'L')\nsubgraph.edge('L', 'K')\nsubgraph.edge('K', 'H', label='Update vehicle status')\nsubgraph.edge('J', 'I', label='Yes')\nsubgraph.edge('J', 'K', label='No')\ndot.subgraph(subgraph)\n\n\nprint(\"Generating flowchart... (this will create a file named 'system_workflow.pdf')\")\n# Render the flowchart\ndot.render('system_workflow', format='png', view=False)\n\n# Display the image in the notebook\nfrom IPython.display import Image\nImage('system_workflow.png')\n\nimport pandas as pd\n\n# Create a list of dictionaries describing each feature\nfeature_data = [\n    {'Feature Name': 'Edge Length', 'Type': 'Static', 'Description': 'Physical length of the path in meters.', 'Example': '40.0'},\n    {'Feature Name': 'Edge Slope', 'Type': 'Static', 'Description': 'Gradient of the path (%).', 'Example': '2.0'},\n    {'Feature Name': 'Paved', 'Type': 'Static', 'Description': 'Binary flag (1 if paved, 0 if not).', 'Example': '1'},\n    {'Feature Name': 'Time of Day', 'Type': 'Dynamic', 'Description': 'Hour of the day (0-23).', 'Example': '14.5'},\n    {'Feature Name': 'Congestion', 'Type': 'Dynamic', 'Description': 'Number of vehicles on the edge.', 'Example': '2'},\n    {'Feature Name': 'Rain Intensity', 'Type': 'Dynamic (Weather)', 'Description': 'Categorical (0:None, 1:Light, 2:Mod, 3:Heavy).', 'Example': '2'},\n    {'Feature Name': 'Heat Stress', 'Type': 'Dynamic (Weather)', 'Description': 'Categorical (0:Norm, 1:High, 2:V.High).', 'Example': '1'},\n    {'Feature Name': 'Wind Hazard', 'Type': 'Dynamic (Weather)', 'Description': 'Binary flag (1 if hazardous winds).', 'Example': '0'},\n    {'Feature Name': 'Soil Condition', 'Type': 'Dynamic (Site)', 'Description': 'Categorical (0:Dry, 1:Damp, 2:Muddy).', 'Example': '2'},\n    {'Feature Name': 'Vehicle Type', 'Type': 'Dynamic (Task)', 'Description': 'Binary flag (1 if truck, 0 if forklift).', 'Example': '1'},\n]\n\n# Create a Pandas DataFrame\nfeatures_df = pd.DataFrame(feature_data)\n\nprint(\"--- Table 1: GNN Input Features ---\")\n# Use to_markdown() for a clean, paper-ready format\nprint(features_df.to_markdown(index=False))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\n# Create a test set from the generated data\ntest_size = int(0.2 * len(dataset_df))\ntest_df = dataset_df.iloc[-test_size:]\n\nactual_means = []\npredicted_means = []\n\ngnn_model_aware.eval()\nwith torch.no_grad():\n    for _, record in test_df.iterrows():\n        # Get actual value\n        actual_means.append(record['mean_travel_time'])\n\n        # Get GNN prediction\n        pred_mean, _ = predict_travel_time_with_gnn(\n            u_node=record['edge_start_node'], v_node=record['edge_end_node'],\n            arrival_time=SIMULATION_START_TIME + timedelta(hours=record['time_of_day']),\n            weather_df=weather_df, gnn_model=gnn_model_aware,\n            vehicle_type='truck' if record['vehicle_type_truck'] else 'forklift',\n            soil_condition=record['soil_condition'], weather_aware=True\n        )\n        predicted_means.append(pred_mean)\n\n# Calculate performance metrics\nmae = mean_absolute_error(actual_means, predicted_means)\nr2 = r2_score(actual_means, predicted_means)\n\n# Create the scatter plot\nplt.figure(figsize=(8, 8))\nplt.scatter(actual_means, predicted_means, alpha=0.3, label='Predictions')\n# Add the 'perfect prediction' line\nplt.plot([min(actual_means), max(actual_means)], [min(actual_means), max(actual_means)], 'r--', lw=2, label='Perfect Prediction')\n\nplt.title('GNN Prediction Accuracy on Test Set', fontsize=16)\nplt.xlabel('Actual Travel Time (seconds)', fontsize=12)\nplt.ylabel('Predicted Travel Time (seconds)', fontsize=12)\nplt.legend()\nplt.grid(True)\nplt.text(0.05, 0.95, f'MAE: {mae:.2f} sec\\nR¬≤: {r2:.3f}', transform=plt.gca().transAxes,\n         fontsize=12, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\nplt.axis('equal') # Ensure the plot is square\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import networkx as nx\n\n# --- Define the two scenarios ---\n# Scenario 1: Initial plan before disruptions\ninitial_conditions = {\n    'weather': INITIAL_FORECAST,\n    'graph': site_graph,\n    'soil': 0\n}\n\n# Scenario 2: After the storm forecast and path blockage\ndisrupted_conditions = {\n    'weather': updated_forecast, # The new forecast with the storm\n    'graph': broken_down_graph, # The graph with the missing edge\n    'soil': 2 # It's now muddy\n}\n\n# Define a cost function for nx.shortest_path that uses our GNN\ndef gnn_path_cost(u, v, d, gnn_model, conditions):\n    cost, _ = predict_travel_time_with_gnn(\n        u, v, SIMULATION_START_TIME + timedelta(hours=2), conditions['weather'],\n        gnn_model, 'truck', conditions['soil'], weather_aware=True\n    )\n    return cost\n\n# Select a job that is affected by the blockage\njob_to_visualize = {'source': 'Zone_1', 'destination': 'Storage_A'}\n\n# Calculate the optimal paths for this job in both scenarios\npath_initial = nx.shortest_path(initial_conditions['graph'],\n                                source=job_to_visualize['source'], target=job_to_visualize['destination'],\n                                weight=lambda u,v,d: gnn_path_cost(u,v,d, gnn_model_aware, initial_conditions))\n\npath_adapted = nx.shortest_path(disrupted_conditions['graph'],\n                                source=job_to_visualize['source'], target=job_to_visualize['destination'],\n                                weight=lambda u,v,d: gnn_path_cost(u,v,d, gnn_model_aware, disrupted_conditions))\n\n# --- Create the side-by-side plot ---\nfig, axes = plt.subplots(1, 2, figsize=(20, 9))\npos = nx.get_node_attributes(site_graph, 'pos')\n\n# Plot 1: Initial Plan\nax1 = axes[0]\nax1.set_title('Initial Plan (Before Disruptions)', fontsize=16)\nnx.draw(site_graph, pos, with_labels=True, node_size=2500, node_color='skyblue', ax=ax1, arrows=False)\n# Highlight the initial path\npath_edges = list(zip(path_initial, path_initial[1:]))\nnx.draw_networkx_edges(site_graph, pos, edgelist=path_edges, width=4, edge_color='green', ax=ax1, arrowsize=25)\n\n# Plot 2: Adapted Plan\nax2 = axes[1]\nax2.set_title('Adapted Plan (After Storm & Blockage)', fontsize=16)\nnx.draw(site_graph, pos, with_labels=True, node_size=2500, node_color='skyblue', ax=ax2, arrows=False)\n# Mark the blocked path\nnx.draw_networkx_edges(site_graph, pos, edgelist=[('Zone_2', 'Storage_A')], width=3, style='dashed', edge_color='red', ax=ax2)\nax2.text(pos['Zone_2'][0]-15, pos['Zone_2'][1], 'BLOCKED', color='red', fontsize=14, weight='bold')\n# Highlight the new, adapted path\npath_edges_adapted = list(zip(path_adapted, path_adapted[1:]))\nnx.draw_networkx_edges(site_graph, pos, edgelist=path_edges_adapted, width=4, edge_color='blue', ax=ax2, arrowsize=25)\n\n\nfig.suptitle('Visualizing Adaptive Re-planning for a Single Job', fontsize=20)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- CORRECTED VISUALIZATION 1: IMPACT OF RAIN ON A CRITICAL PATH ---\n\n# Select a representative unpaved, sloped edge from the large-scale graph\nedge_u, edge_v = 'Foundation_Pit', 'Building_2_W'\nedge_data = {**site_graph.edges[edge_u, edge_v], 'start_node': edge_u, 'end_node': edge_v}\nprint(f\"Analyzing edge: {edge_u} -> {edge_v} (Length: {edge_data['length']}m, Slope: {edge_data['slope']}%, Paved: {edge_data['paved']})\")\n\nrain_intensities = [0, 1, 2, 3]\nlabels = ['No Rain', 'Light Rain', 'Moderate Rain', 'Heavy Rain']\ntruck_times, forklift_times = [], []\nmock_time = SIMULATION_START_TIME\n\nfor intensity in rain_intensities:\n    mock_weather = pd.Series({'rain_intensity': intensity, 'heat_stress': 0, 'wind_hazard': 0})\n    soil = 0\n    if intensity >= 2: soil = 2\n    elif intensity == 1: soil = 1\n\n    # Use the correct physics function name and unpack the three return values\n    mean_truck, _, _ = calculate_ground_truth_travel(edge_data, 1, mock_weather, 'truck', mock_time, soil)\n    truck_times.append(mean_truck)\n    mean_forklift, _, _ = calculate_ground_truth_travel(edge_data, 1, mock_weather, 'forklift', mock_time, soil)\n    forklift_times.append(mean_forklift)\n\nplt.figure(figsize=(10, 6))\nplt.plot(labels, truck_times, 'o-', label='Truck', color='blue', markersize=8)\nplt.plot(labels, forklift_times, 's--', label='Forklift (more sensitive)', color='orange', markersize=8)\nplt.title('Figure: Impact of Rain on Travel Time for an Unpaved Path', fontsize=16)\nplt.ylabel('Simulated Travel Time (seconds)', fontsize=12)\nplt.xlabel('Rain Intensity', fontsize=12)\nplt.legend(); plt.grid(True, which='both', linestyle='--', linewidth=0.5); plt.tight_layout(); plt.show()\n\n\n# --- CORRECTED VISUALIZATION 2: ADAPTIVE RE-PLANNING ---\n# Select a job that will be directly affected by the planned blockage\njob_to_visualize = {'source': 'Building_1_S', 'destination': 'Laydown_B'}\n# The edge that will be blocked in the simulation\nblocked_edge_viz = ('Building_1_S', 'Main_Gate')\n\n# Define a cost function for nx.shortest_path that uses our GNN\ndef gnn_path_cost(u, v, d, gnn_model, conditions):\n    cost, _ = predict_travel_time_with_gnn(\n        u, v, SIMULATION_START_TIME, conditions['weather'], gnn_model, 'truck', conditions['soil'], weather_aware=True\n    )\n    return cost\n\n# Calculate optimal paths before and after disruption\npath_initial = nx.shortest_path(site_graph, source=job_to_visualize['source'], target=job_to_visualize['destination'],\n                                weight=lambda u,v,d: gnn_path_cost(u,v,d, gnn_model_aware, {'weather': INITIAL_FORECAST, 'soil': 0}))\npath_adapted = nx.shortest_path(broken_down_graph, source=job_to_visualize['source'], target=job_to_visualize['destination'],\n                                weight=lambda u,v,d: gnn_path_cost(u,v,d, gnn_model_aware, {'weather': updated_forecast, 'soil': 2}))\n\n# Create the side-by-side plot\nfig, axes = plt.subplots(1, 2, figsize=(22, 10))\npos = nx.get_node_attributes(site_graph, 'pos')\n\n# Plot 1: Initial Plan\naxes[0].set_title('Initial Plan (Before Disruptions)', fontsize=16)\nnx.draw(site_graph, pos, with_labels=True, node_size=3000, node_color='skyblue', ax=axes[0], arrows=False)\nnx.draw_networkx_edges(site_graph, pos, edgelist=list(zip(path_initial, path_initial[1:])), width=4, edge_color='green', ax=axes[0], arrowsize=25, label=\"Initial Path\")\n\n# Plot 2: Adapted Plan\naxes[1].set_title('Adapted Plan (After Route Blockage)', fontsize=16)\nnx.draw(site_graph, pos, with_labels=True, node_size=3000, node_color='skyblue', ax=axes[1], arrows=False)\nnx.draw_networkx_edges(site_graph, pos, edgelist=[blocked_edge_viz], width=3, style='dashed', edge_color='red', ax=axes[1])\nnode_pos = pos[blocked_edge_viz[0]]\naxes[1].text(node_pos[0], node_pos[1] - 10, 'BLOCKED', color='red', fontsize=14, weight='bold', ha='center')\nnx.draw_networkx_edges(site_graph, pos, edgelist=list(zip(path_adapted, path_adapted[1:])), width=4, edge_color='blue', ax=axes[1], arrowsize=25, label=\"Adapted Path\")\n\nfig.suptitle('Figure: Visualization of Adaptive Re-planning', fontsize=20); plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 4. GENERATE THE \"GREEN vs. LEAN\" TRADE-OFF TABLE ---\n# This block provides the quantitative data for the paper's sustainability discussion.\n\nif pareto_front:\n    # Use the representative solutions identified earlier\n    lean_plan = best_time_solution   # The \"Fastest\" plan\n    green_plan = best_cost_solution  # The \"Cheapest/Greenest\" plan\n\n    # Define the CO2 conversion factor (kg of CO2 per liter of diesel)\n    CO2_FACTOR = 2.68\n\n    # Calculate metrics for the table\n    lean_makespan = lean_plan[0]\n    lean_fuel = lean_plan[1]\n    lean_co2 = lean_fuel * CO2_FACTOR\n\n    green_makespan = green_plan[0]\n    green_fuel = green_plan[1]\n    green_co2 = green_fuel * CO2_FACTOR\n\n    # Calculate the percentage trade-offs\n    # The \"Lean\" plan is the baseline for comparison\n    makespan_increase_pct = ((green_makespan - lean_makespan) / lean_makespan) * 100\n    co2_reduction_pct = ((lean_co2 - green_co2) / lean_co2) * 100\n\n    # Create a Pandas DataFrame for clean formatting\n    tradeoff_data = {\n        'Metric': ['Project Makespan (Hours)', 'Total Fuel Consumed (Liters)', 'Total CO‚ÇÇ Emissions (kg)'],\n        'Lean Plan (Fastest)': [f\"{lean_makespan:.2f}\", f\"{lean_fuel:.2f}\", f\"{lean_co2:.2f}\"],\n        'Green Plan (Most Fuel-Efficient)': [f\"{green_makespan:.2f}\", f\"{green_fuel:.2f}\", f\"{green_co2:.2f}\"],\n        'Trade-Off': [f\"+{makespan_increase_pct:.1f}% Time\", \"-\", f\"-{co2_reduction_pct:.1f}% Emissions\"]\n    }\n    tradeoff_df = pd.DataFrame(tradeoff_data)\n\n    print(\"\\n\\n\" + \"=\"*70)\n    print(\"--- üåç Table: The Green vs. Lean Trade-Off in Construction Logistics üåç ---\")\n    print(\"=\"*70)\n    # Print the table in a format ready to be copied into a paper\n    print(tradeoff_df.to_markdown(index=False))\n    print(\"=\"*70)\n    print(f\"\\nKey Finding: Opting for the 'Green' plan reduces CO‚ÇÇ emissions by {co2_reduction_pct:.1f}% at the cost of a {makespan_increase_pct:.1f}% increase in project makespan.\")\n\nelse:\n    print(\"Cannot generate trade-off table because the Pareto front is empty.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}